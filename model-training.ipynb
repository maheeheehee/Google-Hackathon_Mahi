{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10835671,"sourceType":"datasetVersion","datasetId":6728907},{"sourceId":10855833,"sourceType":"datasetVersion","datasetId":6742936}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers torch pandas numpy scikit-learn streamlit pdf2image pytesseract\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:09:05.749964Z","iopub.execute_input":"2025-02-24T03:09:05.750336Z","iopub.status.idle":"2025-02-24T03:09:09.227302Z","shell.execute_reply.started":"2025-02-24T03:09:05.750308Z","shell.execute_reply":"2025-02-24T03:09:09.226322Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.42.2)\nRequirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\nRequirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\nRequirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\nRequirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\nRequirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (19.0.1)\nRequirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\nRequirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\nRequirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\nRequirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\nRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\nRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\nRequirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    print(f\"GPU Enabled: {torch.cuda.get_device_name(0)}\")\n    print(f\"Total GPUs: {torch.cuda.device_count()}\")\nelse:\n    print(\"No GPU available\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:09:49.389628Z","iopub.execute_input":"2025-02-24T03:09:49.389937Z","iopub.status.idle":"2025-02-24T03:09:49.395683Z","shell.execute_reply.started":"2025-02-24T03:09:49.389912Z","shell.execute_reply":"2025-02-24T03:09:49.394723Z"}},"outputs":[{"name":"stdout","text":"GPU Enabled: Tesla T4\nTotal GPUs: 2\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import pandas as pd\n\n# Load datasets\ndocuments_df = pd.read_csv(\"/kaggle/input/enterprise-dataset/Text docdata/df_file.csv\")  # Document Classification\ncustomer_df = pd.read_csv(\"/kaggle/input/enterprise-dataset/techsupp_data/technical_support_data.csv\")  # Customer Support Data\n\n# Explore datasets\nprint(documents_df.head())\nprint(customer_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:26:59.519008Z","iopub.execute_input":"2025-02-24T03:26:59.519361Z","iopub.status.idle":"2025-02-24T03:26:59.655663Z","shell.execute_reply.started":"2025-02-24T03:26:59.519332Z","shell.execute_reply":"2025-02-24T03:26:59.654866Z"}},"outputs":[{"name":"stdout","text":"                                                Text  Label\n0  Budget to set scene for election\\n \\n Gordon B...      0\n1  Army chiefs in regiments decision\\n \\n Militar...      0\n2  Howard denies split over ID cards\\n \\n Michael...      0\n3  Observers to monitor UK election\\n \\n Minister...      0\n4  Kilroy names election seat target\\n \\n Ex-chat...      0\n                       PROBLEM_TYPE  no_of_cases  Avg_pending_calls  \\\n0   Temperature control not working          170                1.3   \n1  power chord does not tightly fit           12                2.0   \n2             Fan swing not working            5                1.0   \n3           Main switch does not on            3                2.0   \n4        Forgot mobile app password           45                2.3   \n\n   Avg_resol_time  recurrence_freq  Replace_percent  In_warranty_percent  \\\n0              32             0.04              0.0                   75   \n1             150             0.01              0.5                    5   \n2              35             0.02              0.2                   90   \n3               8             0.01              0.7                    5   \n4              54             0.15              0.0                   99   \n\n   Post_warranty_percent  \n0                     25  \n1                     95  \n2                     10  \n3                     95  \n4                      1  \n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import os\n\nannotations_path = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/training_data/annotations\"\nprint(os.listdir(annotations_path))  # List all annotation files\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:27:38.519586Z","iopub.execute_input":"2025-02-24T03:27:38.519884Z","iopub.status.idle":"2025-02-24T03:27:38.541386Z","shell.execute_reply.started":"2025-02-24T03:27:38.519861Z","shell.execute_reply":"2025-02-24T03:27:38.540625Z"}},"outputs":[{"name":"stdout","text":"['0060036622.json', '12052385.json', '12825369.json', '71563825.json', '0011906503.json', '91914407.json', '0012529284.json', '91581919.json', '00837285.json', '91391310.json', '0013255595.json', '0011845203.json', '0060024314.json', '89368010.json', '00920294.json', '93380187.json', '00040534.json', '89386032.json', '82254638.json', '00851772_1780.json', '89817999_8002.json', '00283813.json', '91315069_91315070.json', '00860012_00860014.json', '00836244.json', '0060207528.json', '0060308461.json', '0060214859.json', '01150773_01150774.json', '0012947358.json', '0060173256.json', '80707440_7443.json', '0060094595.json', '91974562.json', '11875011.json', '0030031163.json', '0060080406.json', '92091873.json', '81619511_9513.json', '01197604.json', '0060029036.json', '71206427.json', '0060091229.json', '0001239897.json', '00070353.json', '91856041_6049.json', '0001463448.json', '0011856542.json', '89867723.json', '93351929_93351931.json', '00920222.json', '92094751.json', '01073843.json', '87672097.json', '71366499.json', '0060136394.json', '81186212.json', '00838511_00838525.json', '92094746.json', '00093726.json', '91356315.json', '0001456787.json', '00922237.json', '0011859695.json', '93213298.json', '0011505151.json', '0060302201.json', '80718412_8413.json', '92657391.json', '80728670.json', '0060270727.json', '0001123541.json', '0000971160.json', '0060000813.json', '92081358_1359.json', '91391286.json', '0001477983.json', '93329540.json', '87533049.json', '91104867.json', '92657311_7313.json', '0060165115.json', '0011974919.json', '92433599_92433601.json', '0001485288.json', '0011899960.json', '0071032790.json', '13149651.json', '91939637.json', '01191071_1072.json', '0012602424.json', '81749056_9057.json', '88547278_88547279.json', '0001438955.json', '0060255888.json', '0060308251.json', '71341634.json', '93455715.json', '0060007216.json', '11508234.json', '0000989556.json', '0060068489.json', '71190280.json', '00865872.json', '0001209043.json', '80310840a.json', '12603270.json', '0012199830.json', '00836816.json', '0011838621.json', '0000990274.json', '0011973451.json', '716552.json', '91355841.json', '00851879.json', '92586242.json', '92327794.json', '0060025670.json', '91903177.json', '71108371.json', '0030041455.json', '01408099_01408101.json', '81619486_9488.json', '01122115.json', '0000999294.json', '88057519.json', '91372360.json', '71202511.json', '0011976929.json', '0001129658.json', '0071032807.json', '0060077689.json', '0060262650.json', '00866042.json', '91161344_91161347.json', '81574683.json', '0001463282.json', '71601299.json', '0001476912.json', '92314414.json', '0012529295.json', '81310636.json', '0001118259.json', '92039708_9710.json', '0012178355.json', '87682908.json', '92298125.json', '91361993.json', '660978.json']\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!pip install pytesseract pdf2image opencv-python\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:28:07.443875Z","iopub.execute_input":"2025-02-24T03:28:07.444189Z","iopub.status.idle":"2025-02-24T03:28:10.752212Z","shell.execute_reply.started":"2025-02-24T03:28:07.444166Z","shell.execute_reply":"2025-02-24T03:28:10.751174Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\nRequirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\nRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import os\n\nimage_folder = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/training_data/images\"\nprint(os.listdir(image_folder))  # List available image files\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:29:57.499973Z","iopub.execute_input":"2025-02-24T03:29:57.500359Z","iopub.status.idle":"2025-02-24T03:29:57.521744Z","shell.execute_reply.started":"2025-02-24T03:29:57.500334Z","shell.execute_reply":"2025-02-24T03:29:57.521065Z"}},"outputs":[{"name":"stdout","text":"['0060255888.png', '0011859695.png', '01073843.png', '82254638.png', '81619511_9513.png', '0011838621.png', '71108371.png', '88547278_88547279.png', '0001477983.png', '0060207528.png', '71206427.png', '81310636.png', '00922237.png', '0060024314.png', '0012178355.png', '91581919.png', '00866042.png', '00865872.png', '0001209043.png', '89386032.png', '00070353.png', '88057519.png', '81186212.png', '92094746.png', '80718412_8413.png', '0000989556.png', '91315069_91315070.png', '0060077689.png', '00093726.png', '01408099_01408101.png', '0030041455.png', '93351929_93351931.png', '91104867.png', '92327794.png', '0060302201.png', '92433599_92433601.png', '01150773_01150774.png', '0030031163.png', '13149651.png', '80310840a.png', '0001456787.png', '0012602424.png', '0060173256.png', '00838511_00838525.png', '00851772_1780.png', '0012529295.png', '0060068489.png', '11508234.png', '0060270727.png', '91372360.png', '00836244.png', '91161344_91161347.png', '89867723.png', '12825369.png', '81619486_9488.png', '0001239897.png', '92081358_1359.png', '0012947358.png', '01197604.png', '00836816.png', '0060094595.png', '0001118259.png', '0011856542.png', '81749056_9057.png', '0060214859.png', '71366499.png', '89368010.png', '00837285.png', '0011974919.png', '87672097.png', '0001485288.png', '91856041_6049.png', '0011906503.png', '89817999_8002.png', '92091873.png', '0001123541.png', '92314414.png', '0011845203.png', '11875011.png', '91939637.png', '12603270.png', '0060262650.png', '92586242.png', '0060308251.png', '0071032790.png', '93380187.png', '0001476912.png', '71563825.png', '0060308461.png', '01191071_1072.png', '00920222.png', '81574683.png', '80728670.png', '91361993.png', '0012529284.png', '0001463282.png', '0000971160.png', '0060000813.png', '0012199830.png', '0060036622.png', '716552.png', '00040534.png', '0011973451.png', '0060091229.png', '00920294.png', '91391310.png', '91903177.png', '93455715.png', '0060080406.png', '87533049.png', '0071032807.png', '87682908.png', '0000999294.png', '0060007216.png', '0060025670.png', '0060165115.png', '92039708_9710.png', '71202511.png', '92657391.png', '91355841.png', '12052385.png', '0060136394.png', '0011505151.png', '0013255595.png', '0011899960.png', '92094751.png', '0011976929.png', '0001463448.png', '0060029036.png', '00860012_00860014.png', '0001129658.png', '00851879.png', '0000990274.png', '00283813.png', '91391286.png', '91974562.png', '93329540.png', '80707440_7443.png', '91914407.png', '660978.png', '0001438955.png', '93213298.png', '71190280.png', '01122115.png', '92298125.png', '91356315.png', '71601299.png', '92657311_7313.png', '71341634.png']\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import os\n\nimage_folder = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/training_data/images\"\n\n# List all files in the directory\navailable_images = set(os.listdir(image_folder))\n\n# Given list of image file names\nexpected_images = {\n    '0060255888.png', '0011859695.png', '01073843.png', '82254638.png', \n    '81619511_9513.png', '0011838621.png', '71108371.png', '88547278_88547279.png', \n    '0001477983.png', '0060207528.png', '71206427.png', '81310636.png', '00922237.png', \n    '0060024314.png', '0012178355.png', '91581919.png', '00866042.png', '00865872.png', \n    '0001209043.png', '89386032.png', '00070353.png', '88057519.png', '81186212.png', \n    '92094746.png', '80718412_8413.png', '0000989556.png', '91315069_91315070.png', \n    '0060077689.png', '00093726.png', '01408099_01408101.png', '0030041455.png', \n    '93351929_93351931.png', '91104867.png', '92327794.png', '0060302201.png', \n    '92433599_92433601.png', '01150773_01150774.png', '0030031163.png', '13149651.png', \n    '80310840a.png', '0001456787.png', '0012602424.png', '0060173256.png', \n    '00838511_00838525.png', '00851772_1780.png', '0012529295.png', '0060068489.png', \n    '11508234.png', '0060270727.png', '91372360.png', '00836244.png', '91161344_91161347.png', \n    '89867723.png', '12825369.png', '81619486_9488.png', '0001239897.png', \n    '92081358_1359.png', '0012947358.png', '01197604.png', '00836816.png', \n    '0060094595.png', '0001118259.png', '0011856542.png', '81749056_9057.png', \n    '0060214859.png', '71366499.png', '89368010.png', '00837285.png', '0011974919.png', \n    '87672097.png', '0001485288.png', '91856041_6049.png', '0011906503.png', \n    '89817999_8002.png', '92091873.png', '0001123541.png', '92314414.png', \n    '0011845203.png', '11875011.png', '91939637.png', '12603270.png', '0060262650.png', \n    '92586242.png', '0060308251.png', '0071032790.png', '93380187.png', '0001476912.png', \n    '71563825.png', '0060308461.png', '01191071_1072.png', '00920222.png', '81574683.png', \n    '80728670.png', '91361993.png', '0012529284.png', '0001463282.png', '0000971160.png', \n    '0060000813.png', '0012199830.png', '0060036622.png', '716552.png', '00040534.png', \n    '0011973451.png', '0060091229.png', '00920294.png', '91391310.png', '91903177.png', \n    '93455715.png', '0060080406.png', '87533049.png', '0071032807.png', '87682908.png', \n    '0000999294.png', '0060007216.png', '0060025670.png', '0060165115.png', \n    '92039708_9710.png', '71202511.png', '92657391.png', '91355841.png', '12052385.png', \n    '0060136394.png', '0011505151.png', '0013255595.png', '0011899960.png', \n    '92094751.png', '0011976929.png', '0001463448.png', '0060029036.png', \n    '00860012_00860014.png', '0001129658.png', '00851879.png', '0000990274.png', \n    '00283813.png', '91391286.png', '91974562.png', '93329540.png', '80707440_7443.png', \n    '91914407.png', '660978.png', '0001438955.png', '93213298.png', '71190280.png', \n    '01122115.png', '92298125.png', '91356315.png', '71601299.png', '92657311_7313.png', \n    '71341634.png'\n}\n\n# Find missing and extra files\nmissing_files = expected_images - available_images\nextra_files = available_images - expected_images\n\nprint(f\"Missing files ({len(missing_files)}): {missing_files}\")\nprint(f\"Extra files ({len(extra_files)}): {extra_files}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:31:30.387407Z","iopub.execute_input":"2025-02-24T03:31:30.387700Z","iopub.status.idle":"2025-02-24T03:31:30.399231Z","shell.execute_reply.started":"2025-02-24T03:31:30.387677Z","shell.execute_reply":"2025-02-24T03:31:30.398492Z"}},"outputs":[{"name":"stdout","text":"Missing files (0): set()\nExtra files (0): set()\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\n# Define paths\nimage_folder = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/training_data/images\"\nprocessed_folder = \"/kaggle/working/preprocessed_images\"\n\n# Create directory for processed images\nos.makedirs(processed_folder, exist_ok=True)\n\n# Preprocessing function\ndef preprocess_image(image_path):\n    img = cv2.imread(image_path)  # Load image\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # Apply Gaussian Blur\n    _, binary = cv2.threshold(blurred, 128, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  # Apply Otsu's Thresholding\n    return binary\n\n# Process and save images\nfor filename in os.listdir(image_folder):\n    img_path = os.path.join(image_folder, filename)\n    processed_img = preprocess_image(img_path)\n    \n    # Save the processed image\n    save_path = os.path.join(processed_folder, filename)\n    cv2.imwrite(save_path, processed_img)\n\nprint(\"Preprocessing complete! Processed images saved to:\", processed_folder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:33:34.137158Z","iopub.execute_input":"2025-02-24T03:33:34.137500Z","iopub.status.idle":"2025-02-24T03:33:36.492498Z","shell.execute_reply.started":"2025-02-24T03:33:34.137467Z","shell.execute_reply":"2025-02-24T03:33:36.491653Z"}},"outputs":[{"name":"stdout","text":"Preprocessing complete! Processed images saved to: /kaggle/working/preprocessed_images\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport pytesseract\nimport numpy as np\nimport os\nimport json\n\n# Set Tesseract OCR path if needed (Windows users may need to specify it)\n# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n\n# Path to images\nimage_folder = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/training_data/images\"\n\n# Output JSON file to store extracted data\noutput_data = {}\n\n# List all images\nimage_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n\ndef preprocess_image(image_path):\n    \"\"\" Load and preprocess an image (grayscale, thresholding) \"\"\"\n    image = cv2.imread(image_path)\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n    _, thresh = cv2.threshold(blurred, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    return image, gray, thresh\n\ndef extract_text(thresh_image):\n    \"\"\" Perform OCR to extract text from an image \"\"\"\n    text = pytesseract.image_to_string(thresh_image, config='--psm 6')\n    return text.strip()\n\ndef detect_contours(image, gray, original_image, filename):\n    \"\"\" Detect form elements like tables, checkboxes, and store their coordinates \"\"\"\n    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    elements = []\n    for contour in contours:\n        x, y, w, h = cv2.boundingRect(contour)\n        \n        # Condition to filter only relevant elements (e.g., checkboxes, tables)\n        if 10 < w < 300 and 10 < h < 300:\n            elements.append({\"x\": x, \"y\": y, \"width\": w, \"height\": h})\n\n            # Draw rectangle around detected elements\n            cv2.rectangle(original_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n    \n    # Save processed image with detected elements\n    output_path = os.path.join(\"processed_images\", f\"processed_{filename}\")\n    os.makedirs(\"processed_images\", exist_ok=True)\n    cv2.imwrite(output_path, original_image)\n\n    return elements\n\n# Process each image\nfor filename in image_files:\n    image_path = os.path.join(image_folder, filename)\n\n    # Preprocess\n    image, gray, thresh = preprocess_image(image_path)\n\n    # Extract text\n    extracted_text = extract_text(thresh)\n\n    # Detect form elements\n    detected_elements = detect_contours(image, gray, image.copy(), filename)\n\n    # Store data\n    output_data[filename] = {\n        \"text\": extracted_text,\n        \"form_elements\": detected_elements\n    }\n\n# Save extracted data to JSON\nwith open(\"extracted_data.json\", \"w\") as f:\n    json.dump(output_data, f, indent=4)\n\nprint(\"Processing complete! Extracted data saved to 'extracted_data.json'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:42:20.488853Z","iopub.execute_input":"2025-02-24T03:42:20.489178Z","iopub.status.idle":"2025-02-24T03:44:56.553600Z","shell.execute_reply.started":"2025-02-24T03:42:20.489151Z","shell.execute_reply":"2025-02-24T03:44:56.552589Z"}},"outputs":[{"name":"stdout","text":"Processing complete! Extracted data saved to 'extracted_data.json'.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import re\nimport pandas as pd\n\n# Load extracted JSON data\nwith open(\"extracted_data.json\", \"r\") as f:\n    extracted_data = json.load(f)\n\n# Regex patterns for key fields\npatterns = {\n    \"date\": r\"\\b(\\d{2}[/\\-]\\d{2}[/\\-]\\d{4}|\\d{4}[/\\-]\\d{2}[/\\-]\\d{2})\\b\",\n    \"invoice_no\": r\"\\b(INV[-\\s]?\\d+|Invoice\\s?#?\\s?\\d+)\\b\",\n    \"email\": r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\",\n    \"phone\": r\"\\b\\d{10}\\b\"\n}\n\n# Process extracted text\nstructured_data = []\nfor filename, data in extracted_data.items():\n    text = data[\"text\"]\n    \n    extracted_info = {key: re.findall(pattern, text) for key, pattern in patterns.items()}\n    \n    structured_data.append({\n        \"Filename\": filename,\n        \"Extracted_Text\": text,\n        \"Date\": extracted_info[\"date\"][0] if extracted_info[\"date\"] else \"\",\n        \"Invoice_No\": extracted_info[\"invoice_no\"][0] if extracted_info[\"invoice_no\"] else \"\",\n        \"Email\": extracted_info[\"email\"][0] if extracted_info[\"email\"] else \"\",\n        \"Phone\": extracted_info[\"phone\"][0] if extracted_info[\"phone\"] else \"\"\n    })\n\n# Save to CSV\ndf = pd.DataFrame(structured_data)\ndf.to_csv(\"structured_data.csv\", index=False)\n\nprint(\"Data processing complete! Structured data saved to 'structured_data.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:47:01.398529Z","iopub.execute_input":"2025-02-24T03:47:01.398874Z","iopub.status.idle":"2025-02-24T03:47:01.433245Z","shell.execute_reply.started":"2025-02-24T03:47:01.398843Z","shell.execute_reply":"2025-02-24T03:47:01.432490Z"}},"outputs":[{"name":"stdout","text":"Data processing complete! Structured data saved to 'structured_data.csv'.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\n\ndef extract_table_from_image(image_path):\n    \"\"\" Extracts tabular data from an image using OpenCV. \"\"\"\n    image = cv2.imread(image_path)\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Apply adaptive thresholding to detect edges\n    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n\n    # Detect horizontal and vertical lines\n    kernel_h = np.ones((1, 50), np.uint8)\n    kernel_v = np.ones((50, 1), np.uint8)\n\n    horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_h)\n    vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_v)\n\n    # Combine horizontal and vertical lines\n    table_mask = cv2.add(horizontal_lines, vertical_lines)\n\n    # Find contours of table elements\n    contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    table_cells = []\n    for contour in contours:\n        x, y, w, h = cv2.boundingRect(contour)\n        if w > 30 and h > 20:  # Filter small elements\n            table_cells.append((x, y, w, h))\n\n    # Sort by row and column\n    table_cells = sorted(table_cells, key=lambda c: (c[1], c[0]))\n\n    return table_cells\n\n# Process each image and extract tables\ntable_data = []\nfor filename in image_files:\n    image_path = os.path.join(image_folder, filename)\n    detected_cells = extract_table_from_image(image_path)\n\n    table_data.append({\n        \"Filename\": filename,\n        \"Detected_Cells\": detected_cells\n    })\n\n# Save to JSON\nwith open(\"table_data.json\", \"w\") as f:\n    json.dump(table_data, f, indent=4)\n\nprint(\"Table extraction complete! Data saved to 'table_data.json'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:47:42.411196Z","iopub.execute_input":"2025-02-24T03:47:42.411484Z","iopub.status.idle":"2025-02-24T03:47:44.206388Z","shell.execute_reply.started":"2025-02-24T03:47:42.411462Z","shell.execute_reply":"2025-02-24T03:47:44.205398Z"}},"outputs":[{"name":"stdout","text":"Table extraction complete! Data saved to 'table_data.json'.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport cv2\nimport pytesseract\n\nimport cv2\nimport pytesseract\nimport pandas as pd\n\ndef assign_text_to_cells(image_path, detected_cells):\n    \"\"\" Extract text from detected table cells using OCR. \"\"\"\n    image = cv2.imread(image_path)\n    extracted_rows = []\n\n    for (x, y, w, h) in detected_cells:\n        cell_roi = image[y:y+h, x:x+w]\n        cell_text = pytesseract.image_to_string(cell_roi, config='--psm 6').strip()\n        extracted_rows.append((x, y, cell_text))\n\n    # ✅ FIX: Ensure cells are sorted properly before converting to DataFrame\n    extracted_rows.sort(key=lambda cell: (cell[1], cell[0]))  # Sort by Y first, then X\n\n    # Convert to DataFrame\n    table_df = pd.DataFrame(extracted_rows, columns=[\"X\", \"Y\", \"Text\"])\n    return table_df\n\n\n# Ensure the \"tables\" directory exists before saving\nos.makedirs(\"tables\", exist_ok=True)\n\n# Process each image and extract structured tables\ncsv_data = []\nfor entry in table_data:\n    filename = entry[\"Filename\"]\n    image_path = os.path.join(image_folder, filename)\n    detected_cells = entry[\"Detected_Cells\"]\n\n    table_df = assign_text_to_cells(image_path, detected_cells)\n\n    # Save CSV file inside \"tables\" folder\n    csv_path = os.path.join(\"tables\", f\"{filename}.csv\")\n    table_df.to_csv(csv_path, index=False)\n    csv_data.append({\"Filename\": filename, \"CSV_Path\": csv_path})\n\n# Save extracted table file paths\nwith open(\"csv_files.json\", \"w\") as f:\n    json.dump(csv_data, f, indent=4)\n\nprint(\"CSV conversion complete! Tables saved in 'tables/' folder.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:55:35.343169Z","iopub.execute_input":"2025-02-24T03:55:35.343577Z","iopub.status.idle":"2025-02-24T03:56:38.095658Z","shell.execute_reply.started":"2025-02-24T03:55:35.343537Z","shell.execute_reply":"2025-02-24T03:56:38.094855Z"}},"outputs":[{"name":"stdout","text":"CSV conversion complete! Tables saved in 'tables/' folder.\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"import re\nimport pandas as pd\n\ndef clean_text(text):\n    \"\"\" Normalize extracted text: remove noise & fix inconsistencies \"\"\"\n    text = str(text).strip().lower()\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove unwanted characters\n    text = re.sub(r'\\s+', ' ', text)  # Normalize spaces\n    if len(text) < 3:  # If text is too short, assume it's unreadable\n        text = \"[UNREADABLE]\"\n    return text\n\n# Apply cleaning to all CSVs\nfor entry in csv_data:\n    csv_path = entry[\"CSV_Path\"]\n\n    df = pd.read_csv(csv_path)\n    \n    # Clean text column\n    df[\"Text\"] = df[\"Text\"].apply(clean_text)\n\n    # Drop empty or unreadable rows\n    df = df[df[\"Text\"] != \"[UNREADABLE]\"]\n\n    # Save cleaned CSV\n    df.to_csv(csv_path, index=False)\n    print(f\"✅ Cleaned & saved {csv_path}\")\n\nprint(\"Data cleaning complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:56:46.653761Z","iopub.execute_input":"2025-02-24T03:56:46.654063Z","iopub.status.idle":"2025-02-24T03:56:47.005575Z","shell.execute_reply.started":"2025-02-24T03:56:46.654022Z","shell.execute_reply":"2025-02-24T03:56:47.004682Z"}},"outputs":[{"name":"stdout","text":"✅ Cleaned & saved tables/0060255888.png.csv\n✅ Cleaned & saved tables/0011859695.png.csv\n✅ Cleaned & saved tables/01073843.png.csv\n✅ Cleaned & saved tables/82254638.png.csv\n✅ Cleaned & saved tables/81619511_9513.png.csv\n✅ Cleaned & saved tables/0011838621.png.csv\n✅ Cleaned & saved tables/71108371.png.csv\n✅ Cleaned & saved tables/88547278_88547279.png.csv\n✅ Cleaned & saved tables/0001477983.png.csv\n✅ Cleaned & saved tables/0060207528.png.csv\n✅ Cleaned & saved tables/71206427.png.csv\n✅ Cleaned & saved tables/81310636.png.csv\n✅ Cleaned & saved tables/00922237.png.csv\n✅ Cleaned & saved tables/0060024314.png.csv\n✅ Cleaned & saved tables/0012178355.png.csv\n✅ Cleaned & saved tables/91581919.png.csv\n✅ Cleaned & saved tables/00866042.png.csv\n✅ Cleaned & saved tables/00865872.png.csv\n✅ Cleaned & saved tables/0001209043.png.csv\n✅ Cleaned & saved tables/89386032.png.csv\n✅ Cleaned & saved tables/00070353.png.csv\n✅ Cleaned & saved tables/88057519.png.csv\n✅ Cleaned & saved tables/81186212.png.csv\n✅ Cleaned & saved tables/92094746.png.csv\n✅ Cleaned & saved tables/80718412_8413.png.csv\n✅ Cleaned & saved tables/0000989556.png.csv\n✅ Cleaned & saved tables/91315069_91315070.png.csv\n✅ Cleaned & saved tables/0060077689.png.csv\n✅ Cleaned & saved tables/00093726.png.csv\n✅ Cleaned & saved tables/01408099_01408101.png.csv\n✅ Cleaned & saved tables/0030041455.png.csv\n✅ Cleaned & saved tables/93351929_93351931.png.csv\n✅ Cleaned & saved tables/91104867.png.csv\n✅ Cleaned & saved tables/92327794.png.csv\n✅ Cleaned & saved tables/0060302201.png.csv\n✅ Cleaned & saved tables/92433599_92433601.png.csv\n✅ Cleaned & saved tables/01150773_01150774.png.csv\n✅ Cleaned & saved tables/0030031163.png.csv\n✅ Cleaned & saved tables/13149651.png.csv\n✅ Cleaned & saved tables/80310840a.png.csv\n✅ Cleaned & saved tables/0001456787.png.csv\n✅ Cleaned & saved tables/0012602424.png.csv\n✅ Cleaned & saved tables/0060173256.png.csv\n✅ Cleaned & saved tables/00838511_00838525.png.csv\n✅ Cleaned & saved tables/00851772_1780.png.csv\n✅ Cleaned & saved tables/0012529295.png.csv\n✅ Cleaned & saved tables/0060068489.png.csv\n✅ Cleaned & saved tables/11508234.png.csv\n✅ Cleaned & saved tables/0060270727.png.csv\n✅ Cleaned & saved tables/91372360.png.csv\n✅ Cleaned & saved tables/00836244.png.csv\n✅ Cleaned & saved tables/91161344_91161347.png.csv\n✅ Cleaned & saved tables/89867723.png.csv\n✅ Cleaned & saved tables/12825369.png.csv\n✅ Cleaned & saved tables/81619486_9488.png.csv\n✅ Cleaned & saved tables/0001239897.png.csv\n✅ Cleaned & saved tables/92081358_1359.png.csv\n✅ Cleaned & saved tables/0012947358.png.csv\n✅ Cleaned & saved tables/01197604.png.csv\n✅ Cleaned & saved tables/00836816.png.csv\n✅ Cleaned & saved tables/0060094595.png.csv\n✅ Cleaned & saved tables/0001118259.png.csv\n✅ Cleaned & saved tables/0011856542.png.csv\n✅ Cleaned & saved tables/81749056_9057.png.csv\n✅ Cleaned & saved tables/0060214859.png.csv\n✅ Cleaned & saved tables/71366499.png.csv\n✅ Cleaned & saved tables/89368010.png.csv\n✅ Cleaned & saved tables/00837285.png.csv\n✅ Cleaned & saved tables/0011974919.png.csv\n✅ Cleaned & saved tables/87672097.png.csv\n✅ Cleaned & saved tables/0001485288.png.csv\n✅ Cleaned & saved tables/91856041_6049.png.csv\n✅ Cleaned & saved tables/0011906503.png.csv\n✅ Cleaned & saved tables/89817999_8002.png.csv\n✅ Cleaned & saved tables/92091873.png.csv\n✅ Cleaned & saved tables/0001123541.png.csv\n✅ Cleaned & saved tables/92314414.png.csv\n✅ Cleaned & saved tables/0011845203.png.csv\n✅ Cleaned & saved tables/11875011.png.csv\n✅ Cleaned & saved tables/91939637.png.csv\n✅ Cleaned & saved tables/12603270.png.csv\n✅ Cleaned & saved tables/0060262650.png.csv\n✅ Cleaned & saved tables/92586242.png.csv\n✅ Cleaned & saved tables/0060308251.png.csv\n✅ Cleaned & saved tables/0071032790.png.csv\n✅ Cleaned & saved tables/93380187.png.csv\n✅ Cleaned & saved tables/0001476912.png.csv\n✅ Cleaned & saved tables/71563825.png.csv\n✅ Cleaned & saved tables/0060308461.png.csv\n✅ Cleaned & saved tables/01191071_1072.png.csv\n✅ Cleaned & saved tables/00920222.png.csv\n✅ Cleaned & saved tables/81574683.png.csv\n✅ Cleaned & saved tables/80728670.png.csv\n✅ Cleaned & saved tables/91361993.png.csv\n✅ Cleaned & saved tables/0012529284.png.csv\n✅ Cleaned & saved tables/0001463282.png.csv\n✅ Cleaned & saved tables/0000971160.png.csv\n✅ Cleaned & saved tables/0060000813.png.csv\n✅ Cleaned & saved tables/0012199830.png.csv\n✅ Cleaned & saved tables/0060036622.png.csv\n✅ Cleaned & saved tables/716552.png.csv\n✅ Cleaned & saved tables/00040534.png.csv\n✅ Cleaned & saved tables/0011973451.png.csv\n✅ Cleaned & saved tables/0060091229.png.csv\n✅ Cleaned & saved tables/00920294.png.csv\n✅ Cleaned & saved tables/91391310.png.csv\n✅ Cleaned & saved tables/91903177.png.csv\n✅ Cleaned & saved tables/93455715.png.csv\n✅ Cleaned & saved tables/0060080406.png.csv\n✅ Cleaned & saved tables/87533049.png.csv\n✅ Cleaned & saved tables/0071032807.png.csv\n✅ Cleaned & saved tables/87682908.png.csv\n✅ Cleaned & saved tables/0000999294.png.csv\n✅ Cleaned & saved tables/0060007216.png.csv\n✅ Cleaned & saved tables/0060025670.png.csv\n✅ Cleaned & saved tables/0060165115.png.csv\n✅ Cleaned & saved tables/92039708_9710.png.csv\n✅ Cleaned & saved tables/71202511.png.csv\n✅ Cleaned & saved tables/92657391.png.csv\n✅ Cleaned & saved tables/91355841.png.csv\n✅ Cleaned & saved tables/12052385.png.csv\n✅ Cleaned & saved tables/0060136394.png.csv\n✅ Cleaned & saved tables/0011505151.png.csv\n✅ Cleaned & saved tables/0013255595.png.csv\n✅ Cleaned & saved tables/0011899960.png.csv\n✅ Cleaned & saved tables/92094751.png.csv\n✅ Cleaned & saved tables/0011976929.png.csv\n✅ Cleaned & saved tables/0001463448.png.csv\n✅ Cleaned & saved tables/0060029036.png.csv\n✅ Cleaned & saved tables/00860012_00860014.png.csv\n✅ Cleaned & saved tables/0001129658.png.csv\n✅ Cleaned & saved tables/00851879.png.csv\n✅ Cleaned & saved tables/0000990274.png.csv\n✅ Cleaned & saved tables/00283813.png.csv\n✅ Cleaned & saved tables/91391286.png.csv\n✅ Cleaned & saved tables/91974562.png.csv\n✅ Cleaned & saved tables/93329540.png.csv\n✅ Cleaned & saved tables/80707440_7443.png.csv\n✅ Cleaned & saved tables/91914407.png.csv\n✅ Cleaned & saved tables/660978.png.csv\n✅ Cleaned & saved tables/0001438955.png.csv\n✅ Cleaned & saved tables/93213298.png.csv\n✅ Cleaned & saved tables/71190280.png.csv\n✅ Cleaned & saved tables/01122115.png.csv\n✅ Cleaned & saved tables/92298125.png.csv\n✅ Cleaned & saved tables/91356315.png.csv\n✅ Cleaned & saved tables/71601299.png.csv\n✅ Cleaned & saved tables/92657311_7313.png.csv\n✅ Cleaned & saved tables/71341634.png.csv\nData cleaning complete!\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"import os\n\nempty_files = []\n\nfor entry in csv_data:\n    csv_path = entry[\"CSV_Path\"]\n    \n    df = pd.read_csv(csv_path)\n    \n    if df.empty:\n        empty_files.append(csv_path)\n        os.remove(csv_path)  # Delete the empty file\n        print(f\"🗑️ Deleted empty table: {csv_path}\")\n\n# Save log of removed files\nwith open(\"empty_files_log.txt\", \"w\") as f:\n    f.write(\"\\n\".join(empty_files))\n\nprint(\"✅ Empty table cleanup complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:56:52.528134Z","iopub.execute_input":"2025-02-24T03:56:52.528424Z","iopub.status.idle":"2025-02-24T03:56:52.697707Z","shell.execute_reply.started":"2025-02-24T03:56:52.528403Z","shell.execute_reply":"2025-02-24T03:56:52.696829Z"}},"outputs":[{"name":"stdout","text":"🗑️ Deleted empty table: tables/0060255888.png.csv\n🗑️ Deleted empty table: tables/82254638.png.csv\n🗑️ Deleted empty table: tables/0011838621.png.csv\n🗑️ Deleted empty table: tables/91581919.png.csv\n🗑️ Deleted empty table: tables/0001209043.png.csv\n🗑️ Deleted empty table: tables/00070353.png.csv\n🗑️ Deleted empty table: tables/81186212.png.csv\n🗑️ Deleted empty table: tables/92094746.png.csv\n🗑️ Deleted empty table: tables/80718412_8413.png.csv\n🗑️ Deleted empty table: tables/0000989556.png.csv\n🗑️ Deleted empty table: tables/00093726.png.csv\n🗑️ Deleted empty table: tables/01408099_01408101.png.csv\n🗑️ Deleted empty table: tables/0030041455.png.csv\n🗑️ Deleted empty table: tables/93351929_93351931.png.csv\n🗑️ Deleted empty table: tables/92327794.png.csv\n🗑️ Deleted empty table: tables/0060302201.png.csv\n🗑️ Deleted empty table: tables/92433599_92433601.png.csv\n🗑️ Deleted empty table: tables/0030031163.png.csv\n🗑️ Deleted empty table: tables/0001456787.png.csv\n🗑️ Deleted empty table: tables/0012602424.png.csv\n🗑️ Deleted empty table: tables/0012529295.png.csv\n🗑️ Deleted empty table: tables/91372360.png.csv\n🗑️ Deleted empty table: tables/91161344_91161347.png.csv\n🗑️ Deleted empty table: tables/89867723.png.csv\n🗑️ Deleted empty table: tables/92081358_1359.png.csv\n🗑️ Deleted empty table: tables/01197604.png.csv\n🗑️ Deleted empty table: tables/0011856542.png.csv\n🗑️ Deleted empty table: tables/0060214859.png.csv\n🗑️ Deleted empty table: tables/89368010.png.csv\n🗑️ Deleted empty table: tables/0001485288.png.csv\n🗑️ Deleted empty table: tables/0011906503.png.csv\n🗑️ Deleted empty table: tables/89817999_8002.png.csv\n🗑️ Deleted empty table: tables/92091873.png.csv\n🗑️ Deleted empty table: tables/92314414.png.csv\n🗑️ Deleted empty table: tables/0011845203.png.csv\n🗑️ Deleted empty table: tables/11875011.png.csv\n🗑️ Deleted empty table: tables/91939637.png.csv\n🗑️ Deleted empty table: tables/12603270.png.csv\n🗑️ Deleted empty table: tables/0060308251.png.csv\n🗑️ Deleted empty table: tables/0071032790.png.csv\n🗑️ Deleted empty table: tables/93380187.png.csv\n🗑️ Deleted empty table: tables/0001476912.png.csv\n🗑️ Deleted empty table: tables/71563825.png.csv\n🗑️ Deleted empty table: tables/0060308461.png.csv\n🗑️ Deleted empty table: tables/01191071_1072.png.csv\n🗑️ Deleted empty table: tables/81574683.png.csv\n🗑️ Deleted empty table: tables/80728670.png.csv\n🗑️ Deleted empty table: tables/0012529284.png.csv\n🗑️ Deleted empty table: tables/0060000813.png.csv\n🗑️ Deleted empty table: tables/0012199830.png.csv\n🗑️ Deleted empty table: tables/0060036622.png.csv\n🗑️ Deleted empty table: tables/0060091229.png.csv\n🗑️ Deleted empty table: tables/91391310.png.csv\n🗑️ Deleted empty table: tables/91903177.png.csv\n🗑️ Deleted empty table: tables/93455715.png.csv\n🗑️ Deleted empty table: tables/0071032807.png.csv\n🗑️ Deleted empty table: tables/87682908.png.csv\n🗑️ Deleted empty table: tables/0000999294.png.csv\n🗑️ Deleted empty table: tables/0060007216.png.csv\n🗑️ Deleted empty table: tables/0060025670.png.csv\n🗑️ Deleted empty table: tables/0060165115.png.csv\n🗑️ Deleted empty table: tables/92039708_9710.png.csv\n🗑️ Deleted empty table: tables/92657391.png.csv\n🗑️ Deleted empty table: tables/0013255595.png.csv\n🗑️ Deleted empty table: tables/0011899960.png.csv\n🗑️ Deleted empty table: tables/92094751.png.csv\n🗑️ Deleted empty table: tables/0011976929.png.csv\n🗑️ Deleted empty table: tables/0001463448.png.csv\n🗑️ Deleted empty table: tables/00851879.png.csv\n🗑️ Deleted empty table: tables/0000990274.png.csv\n🗑️ Deleted empty table: tables/00283813.png.csv\n🗑️ Deleted empty table: tables/91391286.png.csv\n🗑️ Deleted empty table: tables/91974562.png.csv\n🗑️ Deleted empty table: tables/80707440_7443.png.csv\n🗑️ Deleted empty table: tables/91914407.png.csv\n🗑️ Deleted empty table: tables/0001438955.png.csv\n🗑️ Deleted empty table: tables/93213298.png.csv\n🗑️ Deleted empty table: tables/71190280.png.csv\n🗑️ Deleted empty table: tables/01122115.png.csv\n🗑️ Deleted empty table: tables/71601299.png.csv\n✅ Empty table cleanup complete!\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport json\n\n# Load CSV file paths\nwith open(\"csv_files.json\", \"r\") as f:\n    csv_data = json.load(f)\n\n# Validate each CSV\nfor entry in csv_data:\n    csv_path = entry[\"CSV_Path\"]\n    \n    if not os.path.exists(csv_path):\n        print(f\"❌ Missing file: {csv_path}\")\n        continue\n    \n    df = pd.read_csv(csv_path)\n\n    # Check for empty/misaligned rows\n    if df.isnull().sum().sum() > 0:\n        print(f\"⚠️ Warning: Missing values found in {csv_path}\")\n\n    # Print sample rows for review\n    print(f\"✅ Preview of {csv_path}:\\n\", df.head(), \"\\n\")\n\nprint(\"CSV validation complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:56:58.761647Z","iopub.execute_input":"2025-02-24T03:56:58.761932Z","iopub.status.idle":"2025-02-24T03:56:58.970451Z","shell.execute_reply.started":"2025-02-24T03:56:58.761908Z","shell.execute_reply":"2025-02-24T03:56:58.969637Z"}},"outputs":[{"name":"stdout","text":"❌ Missing file: tables/0060255888.png.csv\n✅ Preview of tables/0011859695.png.csv:\n    X    Y                                               Text\n0  0  138  epeesses dore sep 2 agency 88088 inc contact e... \n\n✅ Preview of tables/01073843.png.csv:\n     X   Y                                               Text\n0  67  52  cowowo diethyl 33dimethyl2oxo14cyclopentanedic... \n\n❌ Missing file: tables/82254638.png.csv\n✅ Preview of tables/81619511_9513.png.csv:\n     X    Y                                               Text\n0  22  420  ne oraccowsr voume stones wwe oraccoum vowume ...\n1  23  652  jwmorsccoun vou sre waeoraccow vous sont vaueo... \n\n❌ Missing file: tables/0011838621.png.csv\n✅ Preview of tables/71108371.png.csv:\n      X   Y                                               Text\n0  102  66  requested by karl hutchison project number ass... \n\n✅ Preview of tables/88547278_88547279.png.csv:\n     X    Y                                               Text\n0  24   53   quototion nea ire er on ee soe 0 ng iographie...\n1  68  176  quotation ke oe date july 7 1995 one park aven...\n2  67  275  quantities and description hd 8 pk wide header...\n3  66  470  preperation and composition final film supplie...\n4  65  566                            process and colors 61 a \n\n✅ Preview of tables/0001477983.png.csv:\n    X  Y                                               Text\n0  0  0  os of rhode island and providence plantations ... \n\n✅ Preview of tables/0060207528.png.csv:\n    X  Y                                               Text\n0  0  0  laurence charles free lawson inc 260 madison a... \n\n✅ Preview of tables/71206427.png.csv:\n      X  Y                                               Text\n0  339  0  ep prbeese lp 7 item package fixture circlek o... \n\n✅ Preview of tables/81310636.png.csv:\n     X   Y                                               Text\n0  72  60  compound structure litton bionetics compound c... \n\n✅ Preview of tables/00922237.png.csv:\n    X   Y                                               Text\n0  8  12  a po 1534 rev 775 oa a d rurcnasina purchase r... \n\n✅ Preview of tables/0060024314.png.csv:\n    X  Y                                               Text\n0  0  0   city of reidsville chemical management plan 1... \n\n✅ Preview of tables/0012178355.png.csv:\n    X  Y                                               Text\n0  0  0  attachment it specification change proposal br... \n\n❌ Missing file: tables/91581919.png.csv\n✅ Preview of tables/00866042.png.csv:\n     X    Y                                               Text\n0  35  121  wo net 1 rrovecr no 2198 stuoy title proposal ... \n\n✅ Preview of tables/00865872.png.csv:\n     X    Y                                               Text\n0  90  128  compound physical parameters na the ph of a 50... \n\n❌ Missing file: tables/0001209043.png.csv\n✅ Preview of tables/89386032.png.csv:\n     X    Y                                     Text\n0  71  125  experimental pathology laboratories inc \n\n❌ Missing file: tables/00070353.png.csv\n✅ Preview of tables/88057519.png.csv:\n      X    Y                                               Text\n0  399  571  no of cartons brand satin filter 100s satin me... \n\n❌ Missing file: tables/81186212.png.csv\n❌ Missing file: tables/92094746.png.csv\n❌ Missing file: tables/80718412_8413.png.csv\n❌ Missing file: tables/0000989556.png.csv\n✅ Preview of tables/91315069_91315070.png.csv:\n     X    Y                                               Text\n0  40  318  a account stores es 00s f100 a a do ct a a fc sid \n\n⚠️ Warning: Missing values found in tables/0060077689.png.csv\n✅ Preview of tables/0060077689.png.csv:\n      X    Y                                               Text\n0    0    0   arses cy 2 american 7 purchase requisition co...\n1   41   85  aaa sss stamford ct ee se or reno at on pecusr...\n2   98  135  craft technologies ing no shipping re mr steve...\n3  340  205                                                NaN\n4   38  241                                      no shipping r \n\n❌ Missing file: tables/00093726.png.csv\n❌ Missing file: tables/01408099_01408101.png.csv\n❌ Missing file: tables/0030041455.png.csv\n❌ Missing file: tables/93351929_93351931.png.csv\n✅ Preview of tables/91104867.png.csv:\n     X    Y                                               Text\n0  57  121  projected current year budget expenses 19 scco... \n\n❌ Missing file: tables/92327794.png.csv\n❌ Missing file: tables/0060302201.png.csv\n❌ Missing file: tables/92433599_92433601.png.csv\n✅ Preview of tables/01150773_01150774.png.csv:\n      X    Y                                               Text\n0  103  313  pals facsiagle tranidgasion 1 intended only po...\n1  487  445                               geive mark h berlind\n2  511  468                                            sal 5 7 \n\n❌ Missing file: tables/0030031163.png.csv\n✅ Preview of tables/13149651.png.csv:\n     X   Y                                               Text\n0  55  88  scal estimate mba23 rev 11780 tas or bit no ta...\n1  41  89  frac al coa jao woe 23 e110 trb of bi no thon ... \n\n✅ Preview of tables/80310840a.png.csv:\n     X   Y                                               Text\n0  58  99  date january 12 1996 project approval market p... \n\n❌ Missing file: tables/0001456787.png.csv\n❌ Missing file: tables/0012602424.png.csv\n✅ Preview of tables/0060173256.png.csv:\n     X    Y                                               Text\n0   0    0  tae american approved marketing projec tobacco...\n1  37  182                        trans private stock carlton\n2  37  310  elite acca charge gode amount displays carmmtd...\n3  37  765  ep poe ee en ee ees er me ee oe ee se ee geena... \n\n✅ Preview of tables/00838511_00838525.png.csv:\n     X   Y                                               Text\n0  69  59  decision tree estimation of toxic risk fp pout... \n\n✅ Preview of tables/00851772_1780.png.csv:\n     X    Y                                               Text\n0  86  112  information search summary valerian fluid extr... \n\n❌ Missing file: tables/0012529295.png.csv\n✅ Preview of tables/0060068489.png.csv:\n      X    Y                                               Text\n0  502  590  approvals agency product medig soles marketing... \n\n✅ Preview of tables/11508234.png.csv:\n      X   Y                                               Text\n0  561   0  199548 vay no no baw interview 000 315 500 0 0...\n1   71  75  date march 3998 no 199548d lucky strike qualit... \n\n✅ Preview of tables/0060270727.png.csv:\n    X  Y                                               Text\n0  0  0  cigarette report form 2 year covered 1987 2 br... \n\n❌ Missing file: tables/91372360.png.csv\n✅ Preview of tables/00836244.png.csv:\n     X   Y                                               Text\n0  67  55  cowown 24dihydroxypyridine ounce lofillard org... \n\n❌ Missing file: tables/91161344_91161347.png.csv\n❌ Missing file: tables/89867723.png.csv\n✅ Preview of tables/12825369.png.csv:\n    X  Y                                               Text\n0  0  0   laurence charles free lawson inc bulletin adv... \n\n✅ Preview of tables/81619486_9488.png.csv:\n     X    Y                                               Text\n0  67  475  perce ee fe lutradiamond azsas ian pe pt pt a ...\n1  68  729  a a a a a rr rr a a a ttttcurdtcccmrdycccscyrc... \n\n✅ Preview of tables/0001239897.png.csv:\n    X  Y                                               Text\n0  0  0  roping some 10288 ree mame amet ys ies foveras... \n\n❌ Missing file: tables/92081358_1359.png.csv\n✅ Preview of tables/0012947358.png.csv:\n      X    Y                              Text\n0  554  608  rupt bga ma duc ue her 146 me 7  \n\n❌ Missing file: tables/01197604.png.csv\n✅ Preview of tables/00836816.png.csv:\n     X    Y                                               Text\n0  76  129  compound physical parameters a the pil of a 50... \n\n✅ Preview of tables/0060094595.png.csv:\n     X    Y                                               Text\n0  90   54  p loreliard 0 thc research divisio quality con...\n1   7  965                                                 gs \n\n✅ Preview of tables/0001118259.png.csv:\n      X    Y                                       Text\n0   99  327   pobs burleyfines 7 ay rpcbs or rpcbso ce\n1   91  631  rxf fine flue cured stem rrxf or rrxfo ee\n2   88  738                                   es rrbl \n3  235  778                                  rrbb rrbl \n\n❌ Missing file: tables/0011856542.png.csv\n✅ Preview of tables/81749056_9057.png.csv:\n     X    Y                                               Text\n0  62  280   of stores sowrraconn re btr oe lt rr er a a a...\n1  68  594  totals of total fof spempuase outlets numberon... \n\n❌ Missing file: tables/0060214859.png.csv\n✅ Preview of tables/71366499.png.csv:\n    X   Y                                               Text\n0  0  22  he ebess wutasos saw nyz yoskics consoeation c... \n\n❌ Missing file: tables/89368010.png.csv\n✅ Preview of tables/00837285.png.csv:\n     X   Y                                               Text\n0  58  34  compound physical parameters eee a 2 or re se ... \n\n✅ Preview of tables/0011974919.png.csv:\n      X    Y                                               Text\n0    0    0  response code request confirmation to doeteins...\n1  185  609                         response code assigned w25 \n\n✅ Preview of tables/87672097.png.csv:\n     X   Y                                               Text\n0  86  52  omuse hapleine sounce crescent comussono b75 c... \n\n❌ Missing file: tables/0001485288.png.csv\n✅ Preview of tables/91856041_6049.png.csv:\n     X   Y  Text\n0  61  65  a ad \n\n❌ Missing file: tables/0011906503.png.csv\n❌ Missing file: tables/89817999_8002.png.csv\n❌ Missing file: tables/92091873.png.csv\n✅ Preview of tables/0001123541.png.csv:\n      X    Y                                               Text\n0  451  141  quality coord only pate reca jorp tog 173 type... \n\n❌ Missing file: tables/92314414.png.csv\n❌ Missing file: tables/0011845203.png.csv\n❌ Missing file: tables/11875011.png.csv\n❌ Missing file: tables/91939637.png.csv\n❌ Missing file: tables/12603270.png.csv\n✅ Preview of tables/0060262650.png.csv:\n     X  Y                                               Text\n0  15  0  r this fc 3 fug annual meeting accepted sympos... \n\n✅ Preview of tables/92586242.png.csv:\n     X   Y       Text\n0  34  68  be ee yee \n\n❌ Missing file: tables/0060308251.png.csv\n❌ Missing file: tables/0071032790.png.csv\n❌ Missing file: tables/93380187.png.csv\n❌ Missing file: tables/0001476912.png.csv\n❌ Missing file: tables/71563825.png.csv\n❌ Missing file: tables/0060308461.png.csv\n❌ Missing file: tables/01191071_1072.png.csv\n✅ Preview of tables/00920222.png.csv:\n     X    Y                                               Text\n0  17  194  0 1534 rev1079 date cd purcuasina purchase req... \n\n❌ Missing file: tables/81574683.png.csv\n❌ Missing file: tables/80728670.png.csv\n✅ Preview of tables/91361993.png.csv:\n     X   Y                                               Text\n0  62  33  new competitive products reported by c m wiech... \n\n❌ Missing file: tables/0012529284.png.csv\n✅ Preview of tables/0001463282.png.csv:\n     X  Y                                               Text\n0  14  0  recommended proposal attached date 41690 ro 6 ... \n\n✅ Preview of tables/0000971160.png.csv:\n    X  Y                                               Text\n0  0  0  rd quality improvement suggestionsolution form... \n\n❌ Missing file: tables/0060000813.png.csv\n❌ Missing file: tables/0012199830.png.csv\n❌ Missing file: tables/0060036622.png.csv\n✅ Preview of tables/716552.png.csv:\n     X    Y                                          Text\n0  17  386  erancw rousvune rerensovne macon wnsronsacen\n1  18  562       iaventonr aera depletion date 103080 ft \n\n✅ Preview of tables/00040534.png.csv:\n     X   Y                                               Text\n0  73  40  acute toxicity in mice cowrowo 3hydroxy3methyl... \n\n✅ Preview of tables/0011973451.png.csv:\n     X    Y                                               Text\n0  56  103  brandproject name richland kings soft pack dut...\n1  57  192                        markets worldwide duty free\n2  57  277  objective generate incremental volume for bw b...\n3  66  420                          bd valueconscious smokers\n4  57  570       volume start up jest monthly ongoing ted tbd \n\n❌ Missing file: tables/0060091229.png.csv\n⚠️ Warning: Missing values found in tables/00920294.png.csv\n✅ Preview of tables/00920294.png.csv:\n     X    Y  Text\n0  86  743   NaN \n\n❌ Missing file: tables/91391310.png.csv\n❌ Missing file: tables/91903177.png.csv\n❌ Missing file: tables/93455715.png.csv\n✅ Preview of tables/0060080406.png.csv:\n     X    Y                                               Text\n0   0  517  furbo packs package 20 sirsms roms 3500090 tra...\n1  12  626  approvals accounting distribution ne jan 40900... \n\n⚠️ Warning: Missing values found in tables/87533049.png.csv\n✅ Preview of tables/87533049.png.csv:\n      X    Y                                               Text\n0  261  747  for control use only code assigned spo 93 job ...\n1   43  940                                                NaN \n\n❌ Missing file: tables/0071032807.png.csv\n❌ Missing file: tables/87682908.png.csv\n❌ Missing file: tables/0000999294.png.csv\n❌ Missing file: tables/0060007216.png.csv\n❌ Missing file: tables/0060025670.png.csv\n❌ Missing file: tables/0060165115.png.csv\n❌ Missing file: tables/92039708_9710.png.csv\n✅ Preview of tables/71202511.png.csv:\n     X   Y                                               Text\n0  59  86  date oe no 199818 kool natural rights packagin... \n\n❌ Missing file: tables/92657391.png.csv\n✅ Preview of tables/91355841.png.csv:\n     X   Y                                               Text\n0  98  51  gadi ii cece ene een ee competitive activities... \n\n✅ Preview of tables/12052385.png.csv:\n     X   Y                                               Text\n0  12  11  kool project no 1987144k 059552915100 descript... \n\n✅ Preview of tables/0060136394.png.csv:\n    X  Y                                               Text\n0  0  0  8 whas a oo os accounting batten barton dursti... \n\n✅ Preview of tables/0011505151.png.csv:\n      X    Y                                               Text\n0  200  376  paid 1987 icsrt 2 dec1987 accrual 9 442 carryo... \n\n❌ Missing file: tables/0013255595.png.csv\n❌ Missing file: tables/0011899960.png.csv\n❌ Missing file: tables/92094751.png.csv\n❌ Missing file: tables/0011976929.png.csv\n❌ Missing file: tables/0001463448.png.csv\n✅ Preview of tables/0060029036.png.csv:\n      X  Y                                               Text\n0  214  0  sports marketing enterprises document clearanc... \n\n✅ Preview of tables/00860012_00860014.png.csv:\n     X    Y                                               Text\n0  36  113  study title proposal wimoer 3212 provect coord... \n\n✅ Preview of tables/0001129658.png.csv:\n      X    Y                                               Text\n0  451  287                                 chargeback 4162158\n1   70  399                    recierenr company faxno phoneno\n2   71  677  ip you do not receive all the pages please cal...\n3   73  915         operator initials confirmation yes name no \n\n❌ Missing file: tables/00851879.png.csv\n❌ Missing file: tables/0000990274.png.csv\n❌ Missing file: tables/00283813.png.csv\n❌ Missing file: tables/91391286.png.csv\n❌ Missing file: tables/91974562.png.csv\n✅ Preview of tables/93329540.png.csv:\n      X   Y                                               Text\n0  132  60  a yew comperitive products ed by a reid divisi...\n1   76  68  irepor manuf jbrand ype o produ isize o1 ilist... \n\n❌ Missing file: tables/80707440_7443.png.csv\n❌ Missing file: tables/91914407.png.csv\n✅ Preview of tables/660978.png.csv:\n    X  Y                                               Text\n0  0  0  feb d6 grey advertising inc meeting report 825... \n\n❌ Missing file: tables/0001438955.png.csv\n❌ Missing file: tables/93213298.png.csv\n❌ Missing file: tables/71190280.png.csv\n❌ Missing file: tables/01122115.png.csv\n✅ Preview of tables/92298125.png.csv:\n      X    Y                                               Text\n0  187  373  other version of the questionnaire please note... \n\n✅ Preview of tables/91356315.png.csv:\n     X   Y                                               Text\n0  66  60  pe gre cie ey aa lena iin sa ane ei rana colip... \n\n❌ Missing file: tables/71601299.png.csv\n✅ Preview of tables/92657311_7313.png.csv:\n     X    Y                         Text\n0  84  304  a aol oon one a a a pt po a \n\n✅ Preview of tables/71341634.png.csv:\n      X    Y                      Text\n0   68  249  gaz fora no nheao oet tt\n1  417  378                       ons\n2  358  379                      0758 \n\nCSV validation complete!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport pytesseract\nimport cv2\nimport json\n\n# Ensure the tables folder exists\nos.makedirs(\"tables\", exist_ok=True)\n\n# Load existing CSV file paths\ncsv_data_path = \"csv_files.json\"\nif os.path.exists(csv_data_path):\n    with open(csv_data_path, \"r\") as f:\n        csv_data = json.load(f)\nelse:\n    csv_data = []\n\n# Convert CSV data into a dictionary for easy lookup\ncsv_files = {entry[\"Filename\"]: entry[\"CSV_Path\"] for entry in csv_data}\n\n# Function to update or create CSV files\ndef update_or_create_csv(image_path, detected_cells, csv_path):\n    \"\"\" Update existing CSVs or create new ones if missing \"\"\"\n    image = cv2.imread(image_path)\n    extracted_rows = []\n\n    for (x, y, w, h) in detected_cells:\n        cell_roi = image[y:y+h, x:x+w]\n        \n        # Extract text using multiple OCR modes to improve accuracy\n        cell_text = pytesseract.image_to_string(cell_roi, config='--psm 6').strip()\n        if not cell_text:\n            cell_text = pytesseract.image_to_string(cell_roi, config='--psm 3').strip()\n\n        extracted_rows.append((x, y, cell_text))\n\n    # Sort rows (first by Y, then by X)\n    extracted_rows.sort(key=lambda cell: (cell[1], cell[0]))\n\n    # Convert to DataFrame\n    table_df = pd.DataFrame(extracted_rows, columns=[\"X\", \"Y\", \"Text\"])\n\n    # If CSV already exists, update it\n    if os.path.exists(csv_path):\n        existing_df = pd.read_csv(csv_path)\n        \n        # Only update if new data is not empty\n        if not table_df.empty:\n            updated_df = pd.concat([existing_df, table_df]).drop_duplicates().reset_index(drop=True)\n            updated_df.to_csv(csv_path, index=False)\n            print(f\"✅ Updated: {csv_path}\")\n        else:\n            print(f\"⚠️ No new data, keeping existing CSV: {csv_path}\")\n    \n    # If CSV does not exist, create it\n    else:\n        table_df.to_csv(csv_path, index=False)\n        print(f\"✅ Created new: {csv_path}\")\n\n# Process each table entry\nfor entry in table_data:\n    filename = entry[\"Filename\"]\n    image_path = os.path.join(image_folder, filename)\n    detected_cells = entry[\"Detected_Cells\"]\n    csv_path = f\"tables/{filename}.csv\"\n\n    # Check if image exists before processing\n    if not os.path.exists(image_path):\n        print(f\"❌ Missing image: {filename}\")\n        continue\n\n    update_or_create_csv(image_path, detected_cells, csv_path)\n\n# Re-generate CSV file paths JSON\ncsv_data = [\n    {\"Filename\": f, \"CSV_Path\": f\"tables/{f}.csv\"}\n    for f in os.listdir(\"tables\") if f.endswith(\".csv\")\n]\n\nwith open(\"csv_files.json\", \"w\") as f:\n    json.dump(csv_data, f, indent=4)\n\nprint(\"✅ CSV validation & update complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:01:17.301416Z","iopub.execute_input":"2025-02-24T04:01:17.301764Z","iopub.status.idle":"2025-02-24T04:02:20.838041Z","shell.execute_reply.started":"2025-02-24T04:01:17.301730Z","shell.execute_reply":"2025-02-24T04:02:20.837048Z"}},"outputs":[{"name":"stdout","text":"⚠️ No new data, keeping existing CSV: tables/0060255888.png.csv\n✅ Updated: tables/0011859695.png.csv\n✅ Updated: tables/01073843.png.csv\n⚠️ No new data, keeping existing CSV: tables/82254638.png.csv\n✅ Updated: tables/81619511_9513.png.csv\n⚠️ No new data, keeping existing CSV: tables/0011838621.png.csv\n✅ Updated: tables/71108371.png.csv\n✅ Updated: tables/88547278_88547279.png.csv\n✅ Updated: tables/0001477983.png.csv\n✅ Updated: tables/0060207528.png.csv\n✅ Updated: tables/71206427.png.csv\n✅ Updated: tables/81310636.png.csv\n✅ Updated: tables/00922237.png.csv\n✅ Updated: tables/0060024314.png.csv\n✅ Updated: tables/0012178355.png.csv\n⚠️ No new data, keeping existing CSV: tables/91581919.png.csv\n✅ Updated: tables/00866042.png.csv\n✅ Updated: tables/00865872.png.csv\n⚠️ No new data, keeping existing CSV: tables/0001209043.png.csv\n✅ Updated: tables/89386032.png.csv\n⚠️ No new data, keeping existing CSV: tables/00070353.png.csv\n✅ Updated: tables/88057519.png.csv\n⚠️ No new data, keeping existing CSV: tables/81186212.png.csv\n⚠️ No new data, keeping existing CSV: tables/92094746.png.csv\n⚠️ No new data, keeping existing CSV: tables/80718412_8413.png.csv\n⚠️ No new data, keeping existing CSV: tables/0000989556.png.csv\n✅ Updated: tables/91315069_91315070.png.csv\n✅ Updated: tables/0060077689.png.csv\n⚠️ No new data, keeping existing CSV: tables/00093726.png.csv\n⚠️ No new data, keeping existing CSV: tables/01408099_01408101.png.csv\n⚠️ No new data, keeping existing CSV: tables/0030041455.png.csv\n⚠️ No new data, keeping existing CSV: tables/93351929_93351931.png.csv\n✅ Updated: tables/91104867.png.csv\n⚠️ No new data, keeping existing CSV: tables/92327794.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060302201.png.csv\n⚠️ No new data, keeping existing CSV: tables/92433599_92433601.png.csv\n✅ Updated: tables/01150773_01150774.png.csv\n✅ Updated: tables/0030031163.png.csv\n✅ Updated: tables/13149651.png.csv\n✅ Updated: tables/80310840a.png.csv\n⚠️ No new data, keeping existing CSV: tables/0001456787.png.csv\n⚠️ No new data, keeping existing CSV: tables/0012602424.png.csv\n✅ Updated: tables/0060173256.png.csv\n✅ Updated: tables/00838511_00838525.png.csv\n✅ Updated: tables/00851772_1780.png.csv\n⚠️ No new data, keeping existing CSV: tables/0012529295.png.csv\n✅ Updated: tables/0060068489.png.csv\n✅ Updated: tables/11508234.png.csv\n✅ Updated: tables/0060270727.png.csv\n⚠️ No new data, keeping existing CSV: tables/91372360.png.csv\n✅ Updated: tables/00836244.png.csv\n⚠️ No new data, keeping existing CSV: tables/91161344_91161347.png.csv\n⚠️ No new data, keeping existing CSV: tables/89867723.png.csv\n✅ Updated: tables/12825369.png.csv\n✅ Updated: tables/81619486_9488.png.csv\n✅ Updated: tables/0001239897.png.csv\n⚠️ No new data, keeping existing CSV: tables/92081358_1359.png.csv\n✅ Updated: tables/0012947358.png.csv\n⚠️ No new data, keeping existing CSV: tables/01197604.png.csv\n✅ Updated: tables/00836816.png.csv\n✅ Updated: tables/0060094595.png.csv\n✅ Updated: tables/0001118259.png.csv\n⚠️ No new data, keeping existing CSV: tables/0011856542.png.csv\n✅ Updated: tables/81749056_9057.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060214859.png.csv\n✅ Updated: tables/71366499.png.csv\n⚠️ No new data, keeping existing CSV: tables/89368010.png.csv\n✅ Updated: tables/00837285.png.csv\n✅ Updated: tables/0011974919.png.csv\n✅ Updated: tables/87672097.png.csv\n⚠️ No new data, keeping existing CSV: tables/0001485288.png.csv\n✅ Updated: tables/91856041_6049.png.csv\n⚠️ No new data, keeping existing CSV: tables/0011906503.png.csv\n⚠️ No new data, keeping existing CSV: tables/89817999_8002.png.csv\n⚠️ No new data, keeping existing CSV: tables/92091873.png.csv\n✅ Updated: tables/0001123541.png.csv\n⚠️ No new data, keeping existing CSV: tables/92314414.png.csv\n⚠️ No new data, keeping existing CSV: tables/0011845203.png.csv\n⚠️ No new data, keeping existing CSV: tables/11875011.png.csv\n⚠️ No new data, keeping existing CSV: tables/91939637.png.csv\n⚠️ No new data, keeping existing CSV: tables/12603270.png.csv\n✅ Updated: tables/0060262650.png.csv\n✅ Updated: tables/92586242.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060308251.png.csv\n⚠️ No new data, keeping existing CSV: tables/0071032790.png.csv\n⚠️ No new data, keeping existing CSV: tables/93380187.png.csv\n⚠️ No new data, keeping existing CSV: tables/0001476912.png.csv\n⚠️ No new data, keeping existing CSV: tables/71563825.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060308461.png.csv\n⚠️ No new data, keeping existing CSV: tables/01191071_1072.png.csv\n✅ Updated: tables/00920222.png.csv\n⚠️ No new data, keeping existing CSV: tables/81574683.png.csv\n⚠️ No new data, keeping existing CSV: tables/80728670.png.csv\n✅ Updated: tables/91361993.png.csv\n⚠️ No new data, keeping existing CSV: tables/0012529284.png.csv\n✅ Updated: tables/0001463282.png.csv\n✅ Updated: tables/0000971160.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060000813.png.csv\n⚠️ No new data, keeping existing CSV: tables/0012199830.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060036622.png.csv\n✅ Updated: tables/716552.png.csv\n✅ Updated: tables/00040534.png.csv\n✅ Updated: tables/0011973451.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060091229.png.csv\n✅ Updated: tables/00920294.png.csv\n⚠️ No new data, keeping existing CSV: tables/91391310.png.csv\n⚠️ No new data, keeping existing CSV: tables/91903177.png.csv\n⚠️ No new data, keeping existing CSV: tables/93455715.png.csv\n✅ Updated: tables/0060080406.png.csv\n✅ Updated: tables/87533049.png.csv\n⚠️ No new data, keeping existing CSV: tables/0071032807.png.csv\n✅ Updated: tables/87682908.png.csv\n⚠️ No new data, keeping existing CSV: tables/0000999294.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060007216.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060025670.png.csv\n⚠️ No new data, keeping existing CSV: tables/0060165115.png.csv\n⚠️ No new data, keeping existing CSV: tables/92039708_9710.png.csv\n✅ Updated: tables/71202511.png.csv\n⚠️ No new data, keeping existing CSV: tables/92657391.png.csv\n✅ Updated: tables/91355841.png.csv\n✅ Updated: tables/12052385.png.csv\n✅ Updated: tables/0060136394.png.csv\n✅ Updated: tables/0011505151.png.csv\n⚠️ No new data, keeping existing CSV: tables/0013255595.png.csv\n⚠️ No new data, keeping existing CSV: tables/0011899960.png.csv\n⚠️ No new data, keeping existing CSV: tables/92094751.png.csv\n⚠️ No new data, keeping existing CSV: tables/0011976929.png.csv\n⚠️ No new data, keeping existing CSV: tables/0001463448.png.csv\n✅ Updated: tables/0060029036.png.csv\n✅ Updated: tables/00860012_00860014.png.csv\n✅ Updated: tables/0001129658.png.csv\n⚠️ No new data, keeping existing CSV: tables/00851879.png.csv\n⚠️ No new data, keeping existing CSV: tables/0000990274.png.csv\n⚠️ No new data, keeping existing CSV: tables/00283813.png.csv\n⚠️ No new data, keeping existing CSV: tables/91391286.png.csv\n⚠️ No new data, keeping existing CSV: tables/91974562.png.csv\n✅ Updated: tables/93329540.png.csv\n⚠️ No new data, keeping existing CSV: tables/80707440_7443.png.csv\n⚠️ No new data, keeping existing CSV: tables/91914407.png.csv\n✅ Updated: tables/660978.png.csv\n⚠️ No new data, keeping existing CSV: tables/0001438955.png.csv\n⚠️ No new data, keeping existing CSV: tables/93213298.png.csv\n⚠️ No new data, keeping existing CSV: tables/71190280.png.csv\n⚠️ No new data, keeping existing CSV: tables/01122115.png.csv\n✅ Updated: tables/92298125.png.csv\n✅ Updated: tables/91356315.png.csv\n⚠️ No new data, keeping existing CSV: tables/71601299.png.csv\n✅ Updated: tables/92657311_7313.png.csv\n✅ Updated: tables/71341634.png.csv\n✅ CSV validation & update complete!\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport json\n\n# Step 1: Load JSON metadata\nwith open(\"csv_files.json\", \"r\") as f:\n    csv_files = json.load(f)\n\n# Step 2: Process each CSV file\ncleaned_data = []\n\nfor entry in csv_files:\n    csv_path = entry[\"CSV_Path\"]\n\n    # Fix double .csv issue if it exists\n    if csv_path.endswith(\".csv.csv\"):\n        csv_path = csv_path[:-4]  # Remove extra \".csv\"\n\n    if not os.path.exists(csv_path):\n        print(f\"❌ Missing file: {csv_path}\")\n        continue\n\n    # Load CSV\n    df = pd.read_csv(csv_path)\n\n    # Step 3: Clean Data\n    df[\"Text\"] = df[\"Text\"].astype(str).str.replace(r\"\\n\", \" \", regex=True)  # Remove newlines\n    df[\"Text\"] = df[\"Text\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()  # Normalize spaces\n\n    # Remove empty rows (where Text is completely empty)\n    df = df[df[\"Text\"] != \"\"]\n\n    # Save cleaned CSV (overwrite existing file)\n    df.to_csv(csv_path, index=False)\n    \n    # Add to final dataset\n    cleaned_data.append({\"Filename\": entry[\"Filename\"], \"CSV_Path\": csv_path})\n\n# Step 4: Update JSON file with cleaned data\nwith open(\"cleaned_csv_files.json\", \"w\") as f:\n    json.dump(cleaned_data, f, indent=4)\n\nprint(\"✅ Data cleaning & CSV updates complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:04:11.381095Z","iopub.execute_input":"2025-02-24T04:04:11.381390Z","iopub.status.idle":"2025-02-24T04:04:11.753624Z","shell.execute_reply.started":"2025-02-24T04:04:11.381367Z","shell.execute_reply":"2025-02-24T04:04:11.752816Z"}},"outputs":[{"name":"stdout","text":"✅ Data cleaning & CSV updates complete!\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport json\n\n# Load updated JSON metadata\nwith open(\"cleaned_csv_files.json\", \"r\") as f:\n    csv_files = json.load(f)\n\n# Step 1: Validate CSV Outputs\nfor entry in csv_files:\n    csv_path = entry[\"CSV_Path\"]\n\n    if not os.path.exists(csv_path):\n        print(f\"❌ Missing file: {csv_path}\")\n        continue\n\n    # Load CSV\n    df = pd.read_csv(csv_path)\n\n    # Check for misaligned columns\n    if df.isnull().all(axis=1).sum() > 0:\n        print(f\"⚠️ Warning: Possible misaligned columns in {csv_path}\")\n\n    # Display preview\n    print(f\"✅ Preview of {csv_path}:\")\n    print(df.head(), \"\\n\")\n\nprint(\"✅ CSV validation complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:04:51.314594Z","iopub.execute_input":"2025-02-24T04:04:51.314893Z","iopub.status.idle":"2025-02-24T04:04:51.670183Z","shell.execute_reply.started":"2025-02-24T04:04:51.314868Z","shell.execute_reply":"2025-02-24T04:04:51.669316Z"}},"outputs":[{"name":"stdout","text":"✅ Preview of tables/00851772_1780.png.csv:\n    X    Y                                               Text\n0  86  112  information search summary valerian fluid extr...\n1  86  112  INFORMATION SEARCH SUMMARY Valerian Fluid Extr... \n\n✅ Preview of tables/0001463448.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/93351929_93351931.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060308251.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/91161344_91161347.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0012529284.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/92094751.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0030031163.png.csv:\n    X  Y Text\n0  70  0   BO \n\n✅ Preview of tables/92586242.png.csv:\n    X   Y       Text\n0  34  68  be ee yee\n1  34  68  Be ee yee \n\n✅ Preview of tables/00040534.png.csv:\n    X   Y                                               Text\n0  73  40  acute toxicity in mice cowrowo 3hydroxy3methyl...\n1  73  40  ACUTE TOXICITY IN MICE cowrowo 3=Hydroxy-3-met... \n\n✅ Preview of tables/01191071_1072.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/71366499.png.csv:\n   X   Y                                               Text\n0  0  22  he ebess wutasos saw nyz yoskics consoeation c...\n1  0  22  he \\ebess wutasos Saw, NYZ Yoskics consoeation... \n\n✅ Preview of tables/0011974919.png.csv:\n     X    Y                                               Text\n0    0    0  response code request confirmation to doeteins...\n1  185  609                         response code assigned w25\n2    0    0  RESPONSE CODE REQUEST CONFIRMATION To; _doetei...\n3  185  609                       Response Code Assigned: _W25 \n\n✅ Preview of tables/0001476912.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/80718412_8413.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/716552.png.csv:\n    X    Y                                               Text\n0  17  386       erancw rousvune rerensovne macon wnsronsacen\n1  18  562            iaventonr aera depletion date 103080 ft\n2  17  386  [erancw __|_rousvune | rerensovne [macon | wns...\n3  18  562         iavenTonr aera ‘DEPLETION DATE 10/30/80 fT \n\n✅ Preview of tables/91372360.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/81749056_9057.png.csv:\n    X    Y                                               Text\n0  62  280  of stores sowrraconn re btr oe lt rr er a a a ...\n1  68  594  totals of total fof spempuase outlets numberon...\n2  62  280  [+ OF STORES| [sowrraconn re [BTR oe, LT | [rr...\n3  68  594  TOTALS OF TOTAL FOF SPEMPUASE OUTLETS | % |NUM... \n\n✅ Preview of tables/0060308461.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0011906503.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/01122115.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/88057519.png.csv:\n     X    Y                                               Text\n0  399  571  no of cartons brand satin filter 100s satin me...\n1  399  571  No, OF CARTONS BRAND Satin Filter 100's. ‘Sati... \n\n✅ Preview of tables/660978.png.csv:\n   X  Y                                               Text\n0  0  0  feb d6 grey advertising inc meeting report 825...\n1  0  0  FEB D6 GREY ADVERTISING INC.- MEETING REPORT “... \n\n✅ Preview of tables/0060094595.png.csv:\n     X    Y                                               Text\n0   90   54  p loreliard 0 thc research divisio quality con...\n1    7  965                                                 gs\n2   90   54  P. LORELIARD €0., THC. RESEARCH DIVISIO: QUALI...\n3    7  965                                              —_ gs\n4  298  965                                                 —_ \n\n✅ Preview of tables/80728670.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/00865872.png.csv:\n    X    Y                                               Text\n0  90  128  compound physical parameters na the ph of a 50...\n1  90  128  COMPOUND PHYSICAL PARAMETERS na ‘The pH of a 5... \n\n✅ Preview of tables/92081358_1359.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0001456787.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060214859.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0001463282.png.csv:\n    X  Y                                               Text\n0  14  0  recommended proposal attached date 41690 ro 6 ...\n1  14  0  (Recommended Proposal Attached) Date: _4/16/90... \n\n✅ Preview of tables/93380187.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/92298125.png.csv:\n     X    Y                                               Text\n0  187  373  other version of the questionnaire please note...\n1  437  134                                                  |\n2  187  373  other version of the questionnaire. Please not... \n\n✅ Preview of tables/00837285.png.csv:\n    X   Y                                               Text\n0  58  34  compound physical parameters eee a 2 or re se ...\n1  58  34  COMPOUND PHYSICAL PARAMETERS —- eee — a 2 or =... \n\n✅ Preview of tables/91355841.png.csv:\n    X   Y                                               Text\n0  98  51  gadi ii cece ene een ee competitive activities...\n1  98  51  Gadi ii Cece ene een ee COMPETITIVE ACTIVITIES... \n\n✅ Preview of tables/89386032.png.csv:\n    X    Y                                       Text\n0  71  125    experimental pathology laboratories inc\n1  71  125  EXPERIMENTAL PATHOLOGY LABORATORIES, INC. \n\n✅ Preview of tables/0060302201.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/93329540.png.csv:\n     X   Y                                               Text\n0  132  60  a yew comperitive products ed by a reid divisi...\n1   76  68  irepor manuf jbrand ype o produ isize o1 ilist...\n2  132  60  a | yew comperitive PRODUCTS __ ED BY: ‘A. REI...\n3   76  68  IREPOR’ MANUF, JBRAND YPE O PRODU ISIZE O1 ILi... \n\n✅ Preview of tables/00860012_00860014.png.csv:\n    X    Y                                               Text\n0  36  113  study title proposal wimoer 3212 provect coord...\n1  36  113  STUDY TITLE & PROPOSAL WIMOER ‘3212 | PROVECT ... \n\n✅ Preview of tables/92094746.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/91361993.png.csv:\n    X   Y                                               Text\n0  62  33  new competitive products reported by c m wiech...\n1  62  33  NEW COMPETITIVE PRODUCTS REPORTED BY: _C. M, W... \n\n✅ Preview of tables/0060068489.png.csv:\n     X    Y                                               Text\n0  502  590  approvals agency product medig soles marketing...\n1  502  590  APPROVALS: [Agency Product Medig Soles Marketi... \n\n✅ Preview of tables/11508234.png.csv:\n     X   Y                                               Text\n0  561   0  199548 vay no no baw interview 000 315 500 0 0...\n1   71  75  date march 3998 no 199548d lucky strike qualit...\n2  561   0  1995-48 VAY No [| No Baw Interview [| [| [| 00...\n3   71  75  |Date: [March 3,998 | No |_1995-48D | LUCKY ST... \n\n✅ Preview of tables/0001477983.png.csv:\n   X  Y                                               Text\n0  0  0  os of rhode island and providence plantations ...\n1  0  0  os OF RHODE ISLAND AND PROVIDENCE PLANTATIONS ... \n\n✅ Preview of tables/91391310.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060262650.png.csv:\n    X  Y                                               Text\n0  15  0  r this fc 3 fug annual meeting accepted sympos...\n1  15  0  R this fc 3 FUG| Annual Meeting | ACCEPTED SYM... \n\n✅ Preview of tables/00283813.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/71341634.png.csv:\n     X    Y                      Text\n0   68  249  gaz fora no nheao oet tt\n1  417  378                       ons\n2  358  379                      0758\n3   68  249  Gaz Fora no nheao oet TT\n4  358  379                   = 0758, \n\n✅ Preview of tables/91974562.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/81574683.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/91581919.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060077689.png.csv:\n     X    Y                                               Text\n0    0    0  arses cy 2 american 7 purchase requisition com...\n1   41   85  aaa sss stamford ct ee se or reno at on pecusr...\n2   98  135  craft technologies ing no shipping re mr steve...\n3  340  205                                                NaN\n4   38  241                                      no shipping r \n\n✅ Preview of tables/0060270727.png.csv:\n   X  Y                                               Text\n0  0  0  cigarette report form 2 year covered 1987 2 br...\n1  0  0  CIGARETTE REPORT FORM (2) YEAR COVERED: 1987, ... \n\n✅ Preview of tables/0012199830.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0012178355.png.csv:\n   X  Y                                               Text\n0  0  0  attachment it specification change proposal br...\n1  0  0  Attachment IT SPECIFICATION CHANGE PROPOSAL BR... \n\n✅ Preview of tables/00920222.png.csv:\n    X    Y                                               Text\n0  17  194  0 1534 rev1079 date cd purcuasina purchase req...\n1  17  194  0. 1534 REV.10/79 DATE, CD purcuasina PURCHASE... \n\n✅ Preview of tables/00866042.png.csv:\n    X    Y                                               Text\n0  35  121  wo net 1 rrovecr no 2198 stuoy title proposal ...\n1  35  121  wo net — 1) __[rrovecr no,_ 2198 STUOY TITLE P... \n\n✅ Preview of tables/91356315.png.csv:\n    X   Y                                               Text\n0  66  60  pe gre cie ey aa lena iin sa ane ei rana colip...\n1  66  60  Pe GRE Cie ey aa lena iin Sa ane ei Rana | Col... \n\n✅ Preview of tables/0071032790.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/01073843.png.csv:\n    X   Y                                               Text\n0  67  52  cowowo diethyl 33dimethyl2oxo14cyclopentanedic...\n1  67  52  cowowo Diethyl 3,3-Dimethyl-2-oxo-1,4-cyclopen... \n\n✅ Preview of tables/93213298.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0011976929.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/01150773_01150774.png.csv:\n     X    Y                                               Text\n0  103  313  pals facsiagle tranidgasion 1 intended only po...\n1  487  445                               geive mark h berlind\n2  511  468                                            sal 5 7\n3  103  313  “PAls FACSIAGLE TRANIDGASION 1 INTENDED ONLY P...\n4  487  445                              GEIVE MARK H. BERLIND \n\n✅ Preview of tables/0000971160.png.csv:\n   X  Y                                               Text\n0  0  0  rd quality improvement suggestionsolution form...\n1  0  0  R&D QUALITY IMPROVEMENT SUGGESTION/SOLUTION FO... \n\n✅ Preview of tables/0013255595.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060255888.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0001485288.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0001129658.png.csv:\n     X    Y                                               Text\n0  451  287                                 chargeback 4162158\n1   70  399                    recierenr company faxno phoneno\n2   71  677  ip you do not receive all the pages please cal...\n3   73  915         operator initials confirmation yes name no\n4  451  287                              (CHARGEBACK: 4162/158 \n\n✅ Preview of tables/93455715.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0012529295.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/12603270.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/92327794.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/80310840a.png.csv:\n    X   Y                                               Text\n0  58  99  date january 12 1996 project approval market p...\n1  58  99  Date: __January 12, 1996 PROJECT APPROVAL MARK... \n\n✅ Preview of tables/0000989556.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0011845203.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/92433599_92433601.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/12052385.png.csv:\n    X   Y                                               Text\n0  12  11  kool project no 1987144k 059552915100 descript...\n1  12  11  KOOL PROJECT NO, __1987-144-K _ 0595-529-1510-... \n\n✅ Preview of tables/0001118259.png.csv:\n     X    Y                                               Text\n0   99  327           pobs burleyfines 7 ay rpcbs or rpcbso ce\n1   91  631          rxf fine flue cured stem rrxf or rrxfo ee\n2   88  738                                            es rrbl\n3  235  778                                          rrbb rrbl\n4   99  327  | POBS = “Burleyfines 7 | ay] RPCBS or RPCBS-O... \n\n✅ Preview of tables/0060024314.png.csv:\n   X  Y                                               Text\n0  0  0  city of reidsville chemical management plan 19...\n1  0  0  . CITY OF REIDSVILLE CHEMICAL MANAGEMENT PLAN ... \n\n✅ Preview of tables/89368010.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0011856542.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/81619486_9488.png.csv:\n    X    Y                                               Text\n0  67  475  perce ee fe lutradiamond azsas ian pe pt pt a ...\n1  68  729  a a a a a rr rr a a a ttttcurdtcccmrdycccscyrc...\n2  67  475  perce ee fe lutraDiamond | azsas [ian PE pT pT...\n3  68  729  a a a a a rr rr a a a | TTTTCUrd)TCCCMrdYC™~<C... \n\n✅ Preview of tables/11875011.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060207528.png.csv:\n   X  Y                                               Text\n0  0  0  laurence charles free lawson inc 260 madison a...\n1  0  0  LAURENCE, CHARLES, FREE & LAWSON, INC. 260 MAD... \n\n✅ Preview of tables/91914407.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/92091873.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/92039708_9710.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/71206427.png.csv:\n     X  Y                                               Text\n0  339  0  ep prbeese lp 7 item package fixture circlek o...\n1  339  0  EP PRBEESE LP { 7 «ITEM: Package Fixture circl... \n\n✅ Preview of tables/00922237.png.csv:\n   X    Y                                               Text\n0  8   12  a po 1534 rev 775 oa a d rurcnasina purchase r...\n1  8   12  a P.O. 1534 REV. 7/75 | oa a D rurcnasina PURC...\n2  9  774                                                  | \n\n✅ Preview of tables/71202511.png.csv:\n    X   Y                                               Text\n0  59  86  date oe no 199818 kool natural rights packagin...\n1  59  86  Date oe No. | 1998-18 ‘KOOL Natural rights Pac... \n\n✅ Preview of tables/0060080406.png.csv:\n    X    Y                                               Text\n0   0  517  furbo packs package 20 sirsms roms 3500090 tra...\n1  12  626  approvals accounting distribution ne jan 40900...\n2   0  517  FURBO PACKS PACKAGE 2.0. SIRSMS roms 35,000.90...\n3  12  626  APPROVALS ACCOUNTING DISTRIBUTION ne JAN $ 40,... \n\n✅ Preview of tables/81186212.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0001209043.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/00851879.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/91315069_91315070.png.csv:\n    X    Y                                               Text\n0  40  318  a account stores es 00s f100 a a do ct a a fc sid\n1  40  318  =a ACCOUNT | STORES ES 00'S F100 a a DO CT a a... \n\n✅ Preview of tables/0071032807.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060029036.png.csv:\n     X  Y                                               Text\n0  214  0  sports marketing enterprises document clearanc...\n1  214  0  SPORTS MARKETING ENTERPRISES DOCUMENT CLEARANC... \n\n✅ Preview of tables/91856041_6049.png.csv:\n    X   Y  Text\n0  61  65  a ad \n\n✅ Preview of tables/13149651.png.csv:\n    X   Y                                               Text\n0  55  88  scal estimate mba23 rev 11780 tas or bit no ta...\n1  41  89  frac al coa jao woe 23 e110 trb of bi no thon ...\n2  55  88  SCAL ESTIMATE > MBA-23 (Rev. 11780) TAS or Bit...\n3  41  89  Frac AL Coa Jao woe 23 e110) TRB oF Bi No. Tho... \n\n✅ Preview of tables/71601299.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0011859695.png.csv:\n   X    Y                                               Text\n0  0  138  epeesses dore sep 2 agency 88088 inc contact e...\n1  0  138  epeesses Dore; __SeP 2 Agency: 88088) Inc Cont... \n\n✅ Preview of tables/0001239897.png.csv:\n   X  Y                                               Text\n0  0  0  roping some 10288 ree mame amet ys ies foveras...\n1  0  0  roping some 10.288 REE, mame amet ys ies fover... \n\n✅ Preview of tables/0011838621.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/12825369.png.csv:\n   X  Y                                               Text\n0  0  0  laurence charles free lawson inc bulletin adve...\n1  0  0  . LAURENCE, CHARLES, FREE & LAWSON, INC. BULLE... \n\n✅ Preview of tables/71190280.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/92657311_7313.png.csv:\n    X    Y                             Text\n0  84  304      a aol oon one a a a pt po a\n1  84  304  a aol oon one a a | a pT [ po a \n\n✅ Preview of tables/0060036622.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0012602424.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0000999294.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/00836244.png.csv:\n    X   Y                                               Text\n0  67  55  cowown 24dihydroxypyridine ounce lofillard org...\n1  67  55  cowown _2+4-Dihydroxypyridine ounce LOFillard ... \n\n✅ Preview of tables/00920294.png.csv:\n    X    Y              Text\n0  86  743               NaN\n1  86  743  fis 1s for notes \n\n✅ Preview of tables/87682908.png.csv:\n     X    Y Text\n0  123  120   GR \n\n✅ Preview of tables/71563825.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0000990274.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/91939637.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/91391286.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/00070353.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0001438955.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0011973451.png.csv:\n    X    Y                                               Text\n0  56  103  brandproject name richland kings soft pack dut...\n1  57  192                        markets worldwide duty free\n2  57  277  objective generate incremental volume for bw b...\n3  66  420                          bd valueconscious smokers\n4  57  570       volume start up jest monthly ongoing ted tbd \n\n✅ Preview of tables/92314414.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/01408099_01408101.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/89817999_8002.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0030041455.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/82254638.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/91903177.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060173256.png.csv:\n    X    Y                                               Text\n0   0    0  tae american approved marketing projec tobacco...\n1  37  182                        trans private stock carlton\n2  37  310  elite acca charge gode amount displays carmmtd...\n3  37  765  ep poe ee en ee ees er me ee oe ee se ee geena...\n4   0    0  Tae “AMERICAN APPROVED MARKETING PROJEC TOBACC... \n\n✅ Preview of tables/0060025670.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/87533049.png.csv:\n     X    Y                                               Text\n0  261  747  for control use only code assigned spo 93 job ...\n1   43  940                                                NaN\n2  261  747  FOR CONTROL USE ONLY: code Assigned SPO 93 © J...\n3   43  940                                                NaN \n\n✅ Preview of tables/89867723.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060136394.png.csv:\n   X  Y                                               Text\n0  0  0  8 whas a oo os accounting batten barton dursti...\n1  0  0  ®8 WHAS a oo ‘os, ‘Accounting Batten, Barton, ... \n\n✅ Preview of tables/0011899960.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/00093726.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0012947358.png.csv:\n     X    Y                                               Text\n0  554  608                    rupt bga ma duc ue her 146 me 7\n1  554  608  RuP.t] BGA.| | M.A. duc | [ue Her.| | 14.6. me... \n\n✅ Preview of tables/81310636.png.csv:\n    X   Y                                               Text\n0  72  60  compound structure litton bionetics compound c...\n1  72  60  COMPOUND STRUCTURE Litton Bionetics COMPOUND C... \n\n✅ Preview of tables/0011505151.png.csv:\n     X    Y                                               Text\n0  200  376  paid 1987 icsrt 2 dec1987 accrual 9 442 carryo...\n1  200  376  PAID 1987, —“(i‘«C*‘*SRT 2 DEC_1987 ACCRUAL 9,... \n\n✅ Preview of tables/88547278_88547279.png.csv:\n    X    Y                                               Text\n0  24   53  quototion nea ire er on ee soe 0 ng iographie ...\n1  68  176  quotation ke oe date july 7 1995 one park aven...\n2  67  275  quantities and description hd 8 pk wide header...\n3  66  470  preperation and composition final film supplie...\n4  65  566                            process and colors 61 a \n\n✅ Preview of tables/01197604.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/00838511_00838525.png.csv:\n    X   Y                                               Text\n0  69  59  decision tree estimation of toxic risk fp pout...\n1  69  59  DECISION TREE ESTIMATION OF TOXIC RISK FP pout... \n\n✅ Preview of tables/71108371.png.csv:\n     X   Y                                               Text\n0  102  66  requested by karl hutchison project number ass...\n1  102  66  ‘Requested by: Karl Hutchison Project Number: ... \n\n✅ Preview of tables/0060000813.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/91104867.png.csv:\n    X    Y                                               Text\n0  57  121  projected current year budget expenses 19 scco...\n1  57  121  PROJECTED CURRENT YEAR BUDGET EXPENSES _19 scc... \n\n✅ Preview of tables/0060007216.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0001123541.png.csv:\n     X    Y                                               Text\n0  451  141  quality coord only pate reca jorp tog 173 type...\n1  451  141  ‘quality coord only pate Rec'a__& jorP tog #17... \n\n✅ Preview of tables/81619511_9513.png.csv:\n    X    Y                                               Text\n0  22  420  ne oraccowsr voume stones wwe oraccoum vowume ...\n1  23  652  jwmorsccoun vou sre waeoraccow vous sont vaueo...\n2  22  420  [ne oraccowsr | voume | stones | wwe oraccoum ...\n3  23  652  jwmorsccoun | vou | sre | waeoraccow | vous | ... \n\n✅ Preview of tables/0060091229.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/0060165115.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/80707440_7443.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/87672097.png.csv:\n    X   Y                                               Text\n0  86  52  omuse hapleine sounce crescent comussono b75 c...\n1  86  52  [omuse Hapleine sounce Crescent —__ comussono ... \n\n✅ Preview of tables/92657391.png.csv:\nEmpty DataFrame\nColumns: [X, Y, Text]\nIndex: [] \n\n✅ Preview of tables/00836816.png.csv:\n    X    Y                                               Text\n0  76  129  compound physical parameters a the pil of a 50...\n1  76  129  ‘COMPOUND PHYSICAL PARAMETERS a | The pil of a... \n\n✅ CSV validation complete!\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"for entry in csv_files:\n    csv_path = entry[\"CSV_Path\"]\n\n    if not os.path.exists(csv_path):\n        continue\n\n    # Load CSV\n    df = pd.read_csv(csv_path)\n\n    # Convert text to lowercase (if needed)\n    df[\"Text\"] = df[\"Text\"].str.lower()\n\n    # Remove duplicate rows\n    df.drop_duplicates(inplace=True)\n\n    # Save cleaned CSV\n    df.to_csv(csv_path, index=False)\n\nprint(\"✅ Further data cleaning complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:05:31.479546Z","iopub.execute_input":"2025-02-24T04:05:31.479833Z","iopub.status.idle":"2025-02-24T04:05:31.782964Z","shell.execute_reply.started":"2025-02-24T04:05:31.479811Z","shell.execute_reply":"2025-02-24T04:05:31.782148Z"}},"outputs":[{"name":"stdout","text":"✅ Further data cleaning complete!\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"import json\n\nwith open(\"extracted_data.json\", \"r\") as f:\n    data = json.load(f)\n\n# Print first 3 key-value pairs\nfor i, (key, value) in enumerate(data.items()):\n    if i == 3:  # Stop after printing 3 entries\n        break\n    print(f\"{key}: {value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:07:09.330550Z","iopub.execute_input":"2025-02-24T04:07:09.330841Z","iopub.status.idle":"2025-02-24T04:07:09.338361Z","shell.execute_reply.started":"2025-02-24T04:07:09.330820Z","shell.execute_reply":"2025-02-24T04:07:09.337511Z"}},"outputs":[{"name":"stdout","text":"0060255888.png: {'text': 'MAEREC AM BROALTASTING COMP AKT\\n‘TRLEVIION HETOORK\\ncee\\nrae\\ntem Cooter 9, 1968\\nBaDO Inc. «\\nNe. Marv Goléemith\\n343 Madisom Avenue New York 10017\\nsi 1 Meee Sree tt\\naAmaricen Tobacco Co.\\nTareytoa Cigarettes\\nrain Sense\\nSerene) ded ‘es eemnyeonettn cleemds\\nPhone booth 120\\nRates | iB\\n;\\nmu 120\\ncu rd\\nSal 160\\n‘THESE CONONERCIALS CAMMOT BE SCHEOULED UNTIL THIS ORPARTNENT MAS\\nBEEN NOTIFIED OF THEIA COOE NUNEERS.\\nPLEASE NOTIFY THA DEPARTIENT OF ANY CHANGES Bt TWE CODE SUNRENCS)\\nPian approved in, of aowme. dupentent span ew aamaning ths Ratsted Giadah ont\\napes ae and plaponand of thee commorstalih)\\nty.\\nAmsrtece Brosbueting Conpeay\\n\" de\\nLy\\nnee cerns env wen  SANDARGS 1 PORE RCE\\na', 'form_elements': []}\n0011859695.png: {'text': 'P a\\nAMEICAN BROADCAST ne COMPANY s “—\\nTELEVIsON METOORE,\\n| 1590 am oe Aan. oe Pon. te Yo\\nerie\\ntun _S0pteaber 25, 1969\\nRn?\\n| 375 Lexington Avenue, Hew York, Mew York 10022\\nCuan, Acerican Tosscco Company\\ni Ret\\nPell Mall Filter tip\\nSkP Sues\\nPita Cleared ‘TiRR2_ APE APPROVAL POAT Esau\\n=Presencer/dirl Rev\" ADAMS T= 66 160\\n\"Pall Rall Filter Tip\" ADP /FeTBLI 120\\nTape WILL POLLOW AS SCOM AS TI ADCEIVE IT FROM THE TAPE\\nREGRARYS\\nPLEASE SOTIFY Tims DOPANTHEST OF ANY CHANDES Du THE CODE SURES)\\nPrank agqunvei we, of crue, Gepemioat ope tine mad planeoeat of the cmmmmsototie).\\n‘Fuads) snahenwt.\\nSy,\\ncried sous Broedaceting Company\\nor nen\\ntt oe\\nORAL Teo Qs\\nPeete\\n(GROARCART STANDARDS AD PRACTICES\\nom ares anv one', 'form_elements': []}\n01073843.png: {'text': 'C Digthy) 3, 3-Disethy}-2-ox0-1, 4-cyclopentanedicarbouylate\\n\\njean LOCil1erd - Organic Chemistry 0 AM23 sau ORSTHLD\\nseconas _ SR ROAM, eves ILLOZ01-8/0/821 egy O/14 781\\n&._8. Tong 6 A. A. Poole eg BE19=25\\nete lat ag\\npoems FO Pe Pe] moe\\nwef fT e2s [] ome\\n\\nPm Dae [ee Toe Pane ee Lae ae |\\nperserasam Per [is cohiseohazcel seolaueol [|\\nlees eens mreerencmmeennn |\\nf2s eT wes Od\\n\\nC zg ao aay ay] ea] ef mt Td\\nfee els\\nJ\\na Ct\\n=\\nmorn |\\njao a 507 Tse] eae] 22 a0 Td\\njz0 ae anes [ssf aot e7 Fane! J |\\nfio Deaf ef aan _\\nCO PE EE)\\ndF\\neen Rees Sa rT ae', 'form_elements': []}\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"import os\nos.rename(\"extracted_data.json\", \"extracted_text.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:08:20.747606Z","iopub.execute_input":"2025-02-24T04:08:20.747893Z","iopub.status.idle":"2025-02-24T04:08:20.760604Z","shell.execute_reply.started":"2025-02-24T04:08:20.747870Z","shell.execute_reply":"2025-02-24T04:08:20.759404Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-b6b7bc7c3007>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"extracted_data.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"extracted_text.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'extracted_data.json' -> 'extracted_text.json'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'extracted_data.json' -> 'extracted_text.json'","output_type":"error"}],"execution_count":66},{"cell_type":"code","source":"import json\n\nwith open(\"extracted_text.json\", \"r\") as f:\n    extracted_text_data = json.load(f)\n\n# Print first 3 extracted text entries\nfor key, value in list(extracted_text_data.items())[:3]:  \n    print(f\"Filename: {key}\")\n    print(\"Extracted Data:\", value)\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:10:52.752657Z","iopub.execute_input":"2025-02-24T04:10:52.753000Z","iopub.status.idle":"2025-02-24T04:10:52.761472Z","shell.execute_reply.started":"2025-02-24T04:10:52.752970Z","shell.execute_reply":"2025-02-24T04:10:52.760715Z"}},"outputs":[{"name":"stdout","text":"Filename: 0060255888.png\nExtracted Data: {'text': 'MAEREC AM BROALTASTING COMP AKT\\n‘TRLEVIION HETOORK\\ncee\\nrae\\ntem Cooter 9, 1968\\nBaDO Inc. «\\nNe. Marv Goléemith\\n343 Madisom Avenue New York 10017\\nsi 1 Meee Sree tt\\naAmaricen Tobacco Co.\\nTareytoa Cigarettes\\nrain Sense\\nSerene) ded ‘es eemnyeonettn cleemds\\nPhone booth 120\\nRates | iB\\n;\\nmu 120\\ncu rd\\nSal 160\\n‘THESE CONONERCIALS CAMMOT BE SCHEOULED UNTIL THIS ORPARTNENT MAS\\nBEEN NOTIFIED OF THEIA COOE NUNEERS.\\nPLEASE NOTIFY THA DEPARTIENT OF ANY CHANGES Bt TWE CODE SUNRENCS)\\nPian approved in, of aowme. dupentent span ew aamaning ths Ratsted Giadah ont\\napes ae and plaponand of thee commorstalih)\\nty.\\nAmsrtece Brosbueting Conpeay\\n\" de\\nLy\\nnee cerns env wen  SANDARGS 1 PORE RCE\\na', 'form_elements': []}\n--------------------------------------------------\nFilename: 0011859695.png\nExtracted Data: {'text': 'P a\\nAMEICAN BROADCAST ne COMPANY s “—\\nTELEVIsON METOORE,\\n| 1590 am oe Aan. oe Pon. te Yo\\nerie\\ntun _S0pteaber 25, 1969\\nRn?\\n| 375 Lexington Avenue, Hew York, Mew York 10022\\nCuan, Acerican Tosscco Company\\ni Ret\\nPell Mall Filter tip\\nSkP Sues\\nPita Cleared ‘TiRR2_ APE APPROVAL POAT Esau\\n=Presencer/dirl Rev\" ADAMS T= 66 160\\n\"Pall Rall Filter Tip\" ADP /FeTBLI 120\\nTape WILL POLLOW AS SCOM AS TI ADCEIVE IT FROM THE TAPE\\nREGRARYS\\nPLEASE SOTIFY Tims DOPANTHEST OF ANY CHANDES Du THE CODE SURES)\\nPrank agqunvei we, of crue, Gepemioat ope tine mad planeoeat of the cmmmmsototie).\\n‘Fuads) snahenwt.\\nSy,\\ncried sous Broedaceting Company\\nor nen\\ntt oe\\nORAL Teo Qs\\nPeete\\n(GROARCART STANDARDS AD PRACTICES\\nom ares anv one', 'form_elements': []}\n--------------------------------------------------\nFilename: 01073843.png\nExtracted Data: {'text': 'C Digthy) 3, 3-Disethy}-2-ox0-1, 4-cyclopentanedicarbouylate\\n\\njean LOCil1erd - Organic Chemistry 0 AM23 sau ORSTHLD\\nseconas _ SR ROAM, eves ILLOZ01-8/0/821 egy O/14 781\\n&._8. Tong 6 A. A. Poole eg BE19=25\\nete lat ag\\npoems FO Pe Pe] moe\\nwef fT e2s [] ome\\n\\nPm Dae [ee Toe Pane ee Lae ae |\\nperserasam Per [is cohiseohazcel seolaueol [|\\nlees eens mreerencmmeennn |\\nf2s eT wes Od\\n\\nC zg ao aay ay] ea] ef mt Td\\nfee els\\nJ\\na Ct\\n=\\nmorn |\\njao a 507 Tse] eae] 22 a0 Td\\njz0 ae anes [ssf aot e7 Fane! J |\\nfio Deaf ef aan _\\nCO PE EE)\\ndF\\neen Rees Sa rT ae', 'form_elements': []}\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load extracted text data\nwith open(\"extracted_text.json\", \"r\") as f:\n    extracted_text_data = json.load(f)\n\n# Load structured CSV data\ncsv_data = pd.read_csv(\"structured_data.csv\")\n\n# Ensure CSV has a column that contains filenames\nfilename_column = \"Filename\"  # Adjust if your column name differs\n\n# Extract base filename without \".csv\" if needed\ncsv_data[\"Base_Filename\"] = csv_data[filename_column].str.replace(\".csv\", \"\", regex=False)\n\n# Map extracted text and other details to CSV\ncsv_data[\"Extracted_Text\"] = csv_data[\"Base_Filename\"].map(lambda x: extracted_text_data.get(x, {}).get(\"text\", \"No Data\"))\ncsv_data[\"Date\"] = csv_data[\"Base_Filename\"].map(lambda x: extracted_text_data.get(x, {}).get(\"Date\", \"Missing\"))\ncsv_data[\"Invoice_No\"] = csv_data[\"Base_Filename\"].map(lambda x: extracted_text_data.get(x, {}).get(\"Invoice_No\", \"Missing\"))\ncsv_data[\"Email\"] = csv_data[\"Base_Filename\"].map(lambda x: extracted_text_data.get(x, {}).get(\"Email\", \"Missing\"))\ncsv_data[\"Phone\"] = csv_data[\"Base_Filename\"].map(lambda x: extracted_text_data.get(x, {}).get(\"Phone\", \"Missing\"))\n\n# Drop helper column\ncsv_data.drop(columns=[\"Base_Filename\"], inplace=True)\n\n# Save merged data\ncsv_data.to_csv(\"merged_data.csv\", index=False)\nprint(\"✅ Merging complete! Check 'merged_data.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:11:14.891130Z","iopub.execute_input":"2025-02-24T04:11:14.891428Z","iopub.status.idle":"2025-02-24T04:11:14.911329Z","shell.execute_reply.started":"2025-02-24T04:11:14.891406Z","shell.execute_reply":"2025-02-24T04:11:14.910436Z"}},"outputs":[{"name":"stdout","text":"✅ Merging complete! Check 'merged_data.csv'.\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"# Apply cleaning\ncleaned_data = [{\"original_text\": text, \"clean_text\": clean_text(text)} for text in extracted_data]\n\n# Save cleaned text\nwith open(\"cleaned_text.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(cleaned_data, f, indent=4)\n\nprint(\"✅ Text Cleaning Done! Data saved to cleaned_text.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:16:48.052371Z","iopub.execute_input":"2025-02-24T04:16:48.052668Z","iopub.status.idle":"2025-02-24T04:16:48.059962Z","shell.execute_reply.started":"2025-02-24T04:16:48.052646Z","shell.execute_reply":"2025-02-24T04:16:48.059085Z"}},"outputs":[{"name":"stdout","text":"✅ Text Cleaning Done! Data saved to cleaned_text.json\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load cleaned text\nwith open(\"cleaned_text.json\", \"r\", encoding=\"utf-8\") as f:\n    cleaned_data = json.load(f)\n\n# Convert to DataFrame\ndf = pd.DataFrame(cleaned_data)\n\n# Add labels (Modify based on actual classification task)\ndf[\"label\"] = [1 if \"important_keyword\" in text.lower() else 0 for text in df[\"clean_text\"]]\n\n# Train/Test Split\nX_train, X_test, y_train, y_test = train_test_split(\n    df[\"clean_text\"], df[\"label\"], test_size=0.2, random_state=42\n)\n\nprint(f\"✅ Data Split Done! Train Size: {len(X_train)}, Test Size: {len(X_test)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:17:26.076539Z","iopub.execute_input":"2025-02-24T04:17:26.076851Z","iopub.status.idle":"2025-02-24T04:17:26.459249Z","shell.execute_reply.started":"2025-02-24T04:17:26.076827Z","shell.execute_reply":"2025-02-24T04:17:26.458441Z"}},"outputs":[{"name":"stdout","text":"✅ Data Split Done! Train Size: 119, Test Size: 30\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Define paths\ntrain_annotations_path = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/training_data/annotations\"\ntest_annotations_path = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/testing_data/annotations\"\n\ntrain_images_path = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/training_data/images\"\ntest_images_path = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/testing_data/images\"\n\n# List annotation files\ntrain_annotations = os.listdir(train_annotations_path)\ntest_annotations = os.listdir(test_annotations_path)\n\n# List image files\ntrain_images = os.listdir(train_images_path)\ntest_images = os.listdir(test_images_path)\n\nprint(f\"✅ Train Annotations: {len(train_annotations)}, Train Images: {len(train_images)}\")\nprint(f\"✅ Test Annotations: {len(test_annotations)}, Test Images: {len(test_images)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:21:12.096206Z","iopub.execute_input":"2025-02-24T04:21:12.096515Z","iopub.status.idle":"2025-02-24T04:21:12.135144Z","shell.execute_reply.started":"2025-02-24T04:21:12.096492Z","shell.execute_reply":"2025-02-24T04:21:12.134446Z"}},"outputs":[{"name":"stdout","text":"✅ Train Annotations: 149, Train Images: 149\n✅ Test Annotations: 50, Test Images: 50\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"import pytesseract\nfrom PIL import Image\nimport os\nimport pandas as pd\n\n# Define correct paths\ntrain_images_path = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/training_data/images\"\ntest_images_path = \"/kaggle/input/enterprise-dataset/FormUnderstanding_data/dataset/testing_data/images\"\n\n# Verify paths\nassert os.path.exists(train_images_path), f\"Train images path not found: {train_images_path}\"\nassert os.path.exists(test_images_path), f\"Test images path not found: {test_images_path}\"\n\n# Function to extract text from images\ndef extract_text_from_images(image_folder):\n    extracted_data = {}\n    for img_file in os.listdir(image_folder):\n        img_path = os.path.join(image_folder, img_file)\n        \n        if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):  # Ensure valid image formats\n            img = Image.open(img_path)\n            extracted_text = pytesseract.image_to_string(img)\n            extracted_data[img_file] = extracted_text  # Store result\n\n    return extracted_data\n\n# Extract text from training and testing images\ntrain_text_data = extract_text_from_images(train_images_path)\ntest_text_data = extract_text_from_images(test_images_path)\n\n# Save extracted data to CSV files\ntrain_text_df = pd.DataFrame(train_text_data.items(), columns=[\"Image\", \"Extracted_Text\"])\ntest_text_df = pd.DataFrame(test_text_data.items(), columns=[\"Image\", \"Extracted_Text\"])\n\ntrain_text_df.to_csv(\"train_extracted_text.csv\", index=False)\ntest_text_df.to_csv(\"test_extracted_text.csv\", index=False)\n\nprint(\"✅ OCR Extraction Complete! Saved to CSV.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T04:25:21.310637Z","iopub.execute_input":"2025-02-24T04:25:21.310991Z","iopub.status.idle":"2025-02-24T04:28:07.238289Z","shell.execute_reply.started":"2025-02-24T04:25:21.310967Z","shell.execute_reply":"2025-02-24T04:28:07.237232Z"}},"outputs":[{"name":"stdout","text":"✅ OCR Extraction Complete! Saved to CSV.\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"import pandas as pd\n\ntrain_path = \"/kaggle/input/final-dataset/train_extracted_text.csv\"\ntest_path = \"/kaggle/input/final-dataset/test_extracted_text.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\n\nprint(\"Train CSV Columns:\", train_df.columns)\nprint(\"Test CSV Columns:\", test_df.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:18:35.681602Z","iopub.execute_input":"2025-02-26T02:18:35.681939Z","iopub.status.idle":"2025-02-26T02:18:35.701645Z","shell.execute_reply.started":"2025-02-26T02:18:35.681908Z","shell.execute_reply":"2025-02-26T02:18:35.700583Z"}},"outputs":[{"name":"stdout","text":"Train CSV Columns: Index(['Image', 'Extracted_Text'], dtype='object')\nTest CSV Columns: Index(['Image', 'Extracted_Text'], dtype='object')\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n# Load the CSV files\ntrain_path = \"/kaggle/input/final-dataset/train_extracted_text.csv\"\ntest_path = \"/kaggle/input/final-dataset/test_extracted_text.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\n\n# Text Cleaning Function\ndef clean_text(text):\n    if pd.isna(text): \n        return \"\"\n    text = str(text).lower()  # Convert to lowercase\n    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Remove special characters\n    return text.strip()\n\n# Apply cleaning\ntrain_df['cleaned_text'] = train_df['Extracted_Text'].apply(clean_text)\ntest_df['cleaned_text'] = test_df['Extracted_Text'].apply(clean_text)\n\n# Save cleaned data\ntrain_df.to_csv(\"/kaggle/working/cleaned_train.csv\", index=False)\ntest_df.to_csv(\"/kaggle/working/cleaned_test.csv\", index=False)\n\nprint(\"✅ Cleaned text saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:19:21.993459Z","iopub.execute_input":"2025-02-26T02:19:21.993801Z","iopub.status.idle":"2025-02-26T02:19:22.048290Z","shell.execute_reply.started":"2025-02-26T02:19:21.993775Z","shell.execute_reply":"2025-02-26T02:19:22.047266Z"}},"outputs":[{"name":"stdout","text":"✅ Cleaned text saved successfully!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n    return text\n\n# Load Data\ntrain_df = pd.read_csv(\"/kaggle/input/final-dataset/train_extracted_text.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/final-dataset/test_extracted_text.csv\")\n\n# Clean Text Data\ntrain_df['cleaned_text'] = train_df['Extracted_Text'].fillna('').apply(clean_text)\ntest_df['cleaned_text'] = test_df['Extracted_Text'].fillna('').apply(clean_text)\n\n# Vectorize using TF-IDF\nvectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\nX_train = vectorizer.fit_transform(train_df['cleaned_text'])\nX_test = vectorizer.transform(test_df['cleaned_text'])\n\n# Topic Modeling (LDA)\nlda = LatentDirichletAllocation(n_components=5, random_state=42)  # 5 topics\ntrain_topics = lda.fit_transform(X_train)\ntest_topics = lda.transform(X_test)\n\n# Assign Topic Labels\ntrain_df['Topic'] = train_topics.argmax(axis=1)\ntest_df['Topic'] = test_topics.argmax(axis=1)\n\n# Save Results\ntrain_df[['Image', 'Topic']].to_csv(\"train_topic_labels.csv\", index=False)\ntest_df[['Image', 'Topic']].to_csv(\"test_topic_labels.csv\", index=False)\n\nprint(\"✅ Topic modeling complete! Check 'train_topic_labels.csv' & 'test_topic_labels.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:28:27.265450Z","iopub.execute_input":"2025-02-26T02:28:27.265884Z","iopub.status.idle":"2025-02-26T02:28:27.618069Z","shell.execute_reply.started":"2025-02-26T02:28:27.265855Z","shell.execute_reply":"2025-02-26T02:28:27.616781Z"}},"outputs":[{"name":"stdout","text":"✅ Topic modeling complete! Check 'train_topic_labels.csv' & 'test_topic_labels.csv'\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\ndef get_top_matches(query, vectorizer, doc_matrix, doc_df, top_n=5):\n    query_vec = vectorizer.transform([query])  # Vectorize query\n    similarities = cosine_similarity(query_vec, doc_matrix).flatten()  # Compute similarity\n    top_indices = similarities.argsort()[-top_n:][::-1]  # Get top N indices\n    \n    return doc_df.iloc[top_indices][['Image', 'Extracted_Text']], similarities[top_indices]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:29:49.105483Z","iopub.execute_input":"2025-02-26T02:29:49.105940Z","iopub.status.idle":"2025-02-26T02:29:49.112288Z","shell.execute_reply.started":"2025-02-26T02:29:49.105902Z","shell.execute_reply":"2025-02-26T02:29:49.110968Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport pickle\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\n# Function to clean text\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n    return text\n\n# Load Data\ntrain_df = pd.read_csv(\"/kaggle/input/final-dataset/train_extracted_text.csv\")\n\n# Clean Text Data\ntrain_df['cleaned_text'] = train_df['Extracted_Text'].fillna('').apply(clean_text)\n\n# Vectorize using TF-IDF\nvectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\nX_train = vectorizer.fit_transform(train_df['cleaned_text'])\n\n# Train LDA Model\nlda = LatentDirichletAllocation(n_components=5, random_state=42)\nlda.fit(X_train)\n\n# Save Model & Vectorizer\nwith open(\"lda_model.pkl\", \"wb\") as f:\n    pickle.dump(lda, f)\n\nwith open(\"vectorizer.pkl\", \"wb\") as f:\n    pickle.dump(vectorizer, f)\n\n# Save dataset (optional, for document similarity)\ntrain_df.to_csv(\"train_extracted_text_cleaned.csv\", index=False)\n\nprint(\"✅ Model training complete! LDA & TF-IDF vectorizer saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:33:11.532778Z","iopub.execute_input":"2025-02-26T02:33:11.533245Z","iopub.status.idle":"2025-02-26T02:33:11.872438Z","shell.execute_reply.started":"2025-02-26T02:33:11.533210Z","shell.execute_reply":"2025-02-26T02:33:11.871152Z"}},"outputs":[{"name":"stdout","text":"✅ Model training complete! LDA & TF-IDF vectorizer saved.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import pandas as pd\nimport joblib\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\n# --- Text Cleaning Function ---\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n    return text\n\n# --- Load Dataset ---\ntrain_df = pd.read_csv(\"/kaggle/input/final-dataset/train_extracted_text.csv\")\n\n# --- Clean Text ---\ntrain_df['cleaned_text'] = train_df['Extracted_Text'].fillna('').apply(clean_text)\n\n# --- Vectorize Text Using TF-IDF ---\nvectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\nX_train = vectorizer.fit_transform(train_df['cleaned_text'])\n\n# --- Train LDA Model (Increase Topics) ---\nlda = LatentDirichletAllocation(n_components=10, random_state=42)  # Increase topics to 10\nlda.fit(X_train)\n\n# --- Extract Top Words Per Topic ---\nwords = vectorizer.get_feature_names_out()\ntopic_words = {}\n\nfor topic_idx, topic in enumerate(lda.components_):\n    top_words = [words[i] for i in topic.argsort()[-10:]]  # Top 10 words\n    topic_words[f\"Topic {topic_idx}\"] = top_words\n\n# --- Assign Meaningful Topic Names (Modify as needed) ---\ntopic_names = [\n    \"Business & Finance\", \"Science & Research\", \"Legal & Policy\", \n    \"Medical & Health\", \"Technology & Engineering\", \"Education & Academia\",\n    \"Government & Regulations\", \"Marketing & Sales\", \"Manufacturing & Industry\", \n    \"Entertainment & Media\"\n]\n\n# --- Save the Model ---\nmodel_data = {\n    \"lda\": lda,\n    \"vectorizer\": vectorizer,\n    \"topic_names\": topic_names,\n    \"topic_words\": topic_words  # Optional: Store topic keywords\n}\n\njoblib.dump(model_data, \"lda_model.pkl\")\nprint(\"✅ Model saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T03:08:13.840586Z","iopub.execute_input":"2025-02-26T03:08:13.841107Z","iopub.status.idle":"2025-02-26T03:08:13.886493Z","shell.execute_reply.started":"2025-02-26T03:08:13.841065Z","shell.execute_reply":"2025-02-26T03:08:13.885037Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-c38f4942c3d8>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# --- Load Dataset ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"large_synthetic_text_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Make sure this file exists!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# --- Clean Text ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'large_synthetic_text_dataset.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'large_synthetic_text_dataset.csv'","output_type":"error"}],"execution_count":39}]}